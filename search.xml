<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>hadoop基础</title>
      <link href="/2021/12/22/hadoop-ji-chu/"/>
      <url>/2021/12/22/hadoop-ji-chu/</url>
      
        <content type="html"><![CDATA[<h2 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h2><h3 id="1-初始hadoop"><a href="#1-初始hadoop" class="headerlink" title="1 初始hadoop"></a>1 初始hadoop</h3><h4 id="1-1-1T文件的操作思考"><a href="#1-1-1T文件的操作思考" class="headerlink" title="1.1 1T文件的操作思考"></a>1.1 1T文件的操作思考</h4><ol><li>   分治思想</li><li>   单机处理大数据的问题</li><li>   集群分布式处理大数据的辩证</li></ol><h5 id="1-1-1-分治思想引入案例"><a href="#1-1-1-分治思想引入案例" class="headerlink" title="1.1.1    分治思想引入案例"></a>1.1.1    分治思想引入案例</h5><ol><li>十万个元素（数字或单词）需要存储，如何存储？<br><a href="https://ibb.co/cxGhwqs">单一遍历复杂度</a></li><li>   如果想查找某一个元素，最简单的遍历方式的复杂度是多少？<br><a href="https://ibb.co/pKxmyKP">多遍历复杂度</a></li></ol><p>•    分而治之的思想非常重要，常见于以下技术：<br>    1.    Redis集群<br>    2.    Hadoop<br>    3.    Hbase<br>    4.    ElasticSearch</p><h5 id="1-1-2-单机处理大数据的问题"><a href="#1-1-2-单机处理大数据的问题" class="headerlink" title="1.1.2    单机处理大数据的问题"></a>1.1.2    单机处理大数据的问题</h5><p>需求：<br>    有一个非常大的文本文件，里面有非常多的行，只有两行内容一样，它们出现在未知的位置，需要查找到它<br>•    假如IO速度是500MB/S<br>•    1T文件读取一遍需要约30分钟<br>•    循环遍历需要N次IO时间<br><a href="https://ibb.co/WHkqWNj">图例</a></p><p>•    分治思想可以使时间降为2次IO<br>•    思考：<br>    •    如何让时间变为分钟、秒级别</p><p>•    假如IO速度是500MB/S<br>•    1T文件读取一遍需要约30分钟<br>•    如何对1TB文件进行排序<br><a href="https://ibb.co/fYqk13G">图例</a></p><p>方式1：外部有序，内部无序。 逐一读入内存排序<br>方式2：逐一读取500M排序，内部有序，    外部无序 ，然后进行归并排序</p><p>需求：<br>•    有一个非常大的文本文件，里面有几百亿行，只有两行内容一样，它们出现在未知的位置，需要查找到它们。<br>•    分钟、秒级别完成<br>•    硬件：*台机器，而且可用的内存500MB</p><p>由于涉及到计算机之间文件传输，千兆带宽，100MB/s<br>拉取网卡100MB/S<br><a href="https://ibb.co/T2BTCSW">图例</a><br>之前忽略了上传时间：1TB/100MB = 10000S     /3600S   = 3H</p><h5 id="1-1-3-集群分布式处理大数据的辩证"><a href="#1-1-3-集群分布式处理大数据的辩证" class="headerlink" title="1.1.3    集群分布式处理大数据的辩证"></a>1.1.3    集群分布式处理大数据的辩证</h5><p>•    2000台真的比一台快吗？<br>•    如果考虑分发上传文件的时间呢？<br>•    如果考虑每天都有1TB数据的产生呢？<br>•    如果增量了一年，最后一天计算数据呢？<br>•    1 天   2*30=1H              3H1M2S<br>•    2天    2H                   3H1M4S<br>•    3天    3H                   3H1M6S<br>•    4天    4H                   3H1M8S</p><h4 id="1-2-hadoop起源"><a href="#1-2-hadoop起源" class="headerlink" title="1.2    hadoop起源"></a>1.2    hadoop起源</h4><h5 id="1-2-1-发展历史"><a href="#1-2-1-发展历史" class="headerlink" title="1.2.1    发展历史"></a>1.2.1    发展历史</h5><blockquote></blockquote><h5 id="1-2-2-核心组件"><a href="#1-2-2-核心组件" class="headerlink" title="1.2.2    核心组件"></a>1.2.2    核心组件</h5><ol><li>   hadoop通用组件 - Hadoop Common包含了其他hadoop模块要用到的库文件和工具</li><li>   分布式文件系统 - Hadoop Distributed File System (HDFS) 运行于通用硬件上的分布式文件系统，高吞吐，高可靠</li><li>   资源管理组件 - Hadoop YARN于2012年引入的组件，用于管理集群中的计算资源并在这些资源上调度用户应用。</li><li>   分布式计算框架 - Hadoop MapReduce 用于处理超大数据集计算的MapReduce编程模型的实现。</li><li>   Hadoop Ozone: An object store for Hadoop.</li><li>   Hadoop Submarine: A machine learning engine for Hadoop</li></ol><h5 id="1-2-3-hadoop关联项目"><a href="#1-2-3-hadoop关联项目" class="headerlink" title="1.2.3    hadoop关联项目"></a>1.2.3    hadoop关联项目</h5><ol><li>   Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeepr、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。</li><li>   Avro™:数据序列化系统</li><li>   Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身，Facebook于2008将 Cassandra 开源。</li><li>   chukwa 是一个开源的用于监控大型分布式系统的数据收集系统。这是构建在 hadoop 的 HDFS 和MapReduce框架之上的，继承了 hadoop 的可伸缩性和健壮性。Chukwa 还包含了一个强大和灵活的工具集，可用于展示、监控和分析已收集的数据。</li><li>   hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。</li><li>   Mahout 提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。</li><li>   Apache Pig 是一个高级过程语言，适合于使用 Hadoop 和 MapReduce 平台来查询大型半结构化数据集。通过允许对分布式数据集进行类似 SQL 的查询，Pig 可以简化 Hadoop 的使用。</li><li>   Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab开源的类Hadoop MapReduce的通用并行框架，拥有MapReduce所具有的优点；但是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。</li><li>   Tez 是 Apache 最新的支持 DAG 作业的开源计算框架。它允许开发者为最终用户构建性能更快、扩展性更好的应用程序。Hadoop传统上是一个大量数据批处理平台。但是，有很多用例需要近乎实时的查询处理性能。还有一些工作则不太适合MapReduce，例如机器学习。Tez的目的就是帮助Hadoop处理这些用例场景。</li><li>   ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</li><li>   HBase是一个分布式的、高可靠性、高性能、面向列、可伸缩的分布式存储系统，该技术来源于Fay Chang所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力</li></ol><h4 id="1-3-HDFS架构"><a href="#1-3-HDFS架构" class="headerlink" title="1.3    HDFS架构"></a>1.3    HDFS架构</h4><h5 id="1-3-1-前提和设计目标"><a href="#1-3-1-前提和设计目标" class="headerlink" title="1.3.1    前提和设计目标"></a>1.3.1    前提和设计目标</h5><ol><li>硬件错误<br> a)    硬件错误是常态而不是异常。<br> b)    HDFS可能由成百上千的服务器所构成，单机故障概率的存在意味着总有一部分服务器不工作的。<br> c)    错误检测和快速自动恢复是HDFS最核心架构目标。 </li><li>流式数据访问<br> a)    运行在HDFS上的应用需要流式访问它们的数据集。<br> b)    HDFS的设计重点是批处理，而不是交互处理。是高吞吐量而不是低延迟。<br> c)    为了提高数据的吞吐量，在关键方面修改POSIX的语义。</li><li>大规模数据集<br> a)    HDFS上的一个典型文件大小一般都在G字节至T字节。TB PB ZB<br> b)    HDFS支持大文件存储。<br> c)    单一HDFS实例能支撑数以千万计的文件。 </li><li>简单的一致性模型<br> a)    HDFS应用遵循“一次写入多次读取”的文件访问模型。<br> b)    简化了数据一致性问题，并且使高吞吐量的数据访问成为可能。<br> c)    Map/Reduce应用或者网络爬虫应用都非常适合这个模型。</li><li>移动计算比移动数据更划算<br> a)    降低网络阻塞的影响，提高系统数据的吞吐量。<br> b)    将计算程序发送到数据所在的主机，比GB级别TB级别的数据移动更便捷。</li><li>异构软硬件平台间的可移植性<br> a)    HDFS在设计的时候就考虑到平台的可移植性。<br> b)    这种特性方便了HDFS作为大规模数据应用平台的推广</li></ol><h5 id="1-3-2-HDFS架构"><a href="#1-3-2-HDFS架构" class="headerlink" title="1.3.2    HDFS架构"></a>1.3.2    HDFS架构</h5><p>问题：<br>    100台服务器，存储空间单个100GB 10T<br>    5T文件如何存储？</p><p>128MB一块      128MB<em>8=1GB    128</em>8*1024=1TB<br>5T数据分成的128MB的块数8192 *5。</p><p>清单：<br>    5TB文件分的块：<br>    元数据：</p><pre class="line-numbers language-none"><code class="language-none">文件名称：web.log大小：5TB创建时间：权限：文件所有者：文件所属的用户组：文件类型：文件块列表信息：0~128*1024*1024 -1：128MB：node1：path,node3:path,node8:path128*1024*1024~2*128*1024*1024 -1：128MB：node2：path,...2*128*1024*1024~3*128*1024*1024 -1：128MB：node3：path0~128*1024*1024 -1：128MB：node1：0~128*1024*1024 -1：128MB：node1：0~128*1024*1024 -1：128MB：node1：0~128*1024*1024 -1：128MB：node1：0~128*1024*1024 -1：128MB：node1：<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://ibb.co/r7Px01F">清单</a><br><a href="https://ibb.co/87YSdjF">图例</a></p><h5 id="1-3-3-NameNode"><a href="#1-3-3-NameNode" class="headerlink" title="1.3.3    NameNode"></a>1.3.3    NameNode</h5><p>NameNode管理文件系统的命名空间</p><ol><li><p>文件和目录的元数据：(运行时，元数据放内存)<br> 文件的block副本个数–通常是3个<br> 修改和访问的时间<br> 访问权限<br> block大小以及组成文件的block列表信息</p></li><li><p>以两种方式在NameNode本地进行持久化：<br> 命名空间镜像文件（fsimage）和编辑日志（edits log）</p></li><li><p>   fsimage文件不记录每个block所在的DataNode信息，这些信息在每次系统启动的时候从DataNode重建。之后DataNode会周期性地通过心跳包向NameNode报告block信息。DataNode向NameNode注册的时候NameNode请求DataNode发送block列表信息。</p><pre class="line-numbers language-none"><code class="language-none">1、文件名称和路径2、文件的大小3、文件的所属关系4、文件的block块大小  128MB  5、文件的副本个数  3   MR  10个副本6、文件的修改时间7、文件的访问时间8、文件的权限9、文件的block列表blk1:0,134217728‬,node1,node13,node26：blockIDblk2:134217728,134217728‬,node7,node89,node1002blk2:134217728*2,134217728‬,node7,node89,node1002blk2:134217728*3,134217728‬,node7,node89,node1002blk2:134217728*4,134217728‬,node7,node89,node1002blk2:134217728*5,134217728‬,node7,node89,node1002blk2:134217728,134217728‬,node7,node89,node1002blk2:134217728,134217728‬,node7,node89,node1002<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>存储结构<br>一个运行的NameNode如下的目录结构，该目录结构在第一次格式化的时候创建<br><a href="https://ibb.co/0M0h5mV">存储结构</a><br>如果属性dfs.namenode.name.dir指定了多个路径，则每个路径中的内容是一样的，尤其是当其中一个是挂载的NFS的时候，这种机制为管理提供了一些弹性。备份数据<br>in_use.lock文件用于NameNode锁定存储目录。这样就防止其他同时运行的NameNode实例使用相同的存储目录。<br>edits表示edits log日志文件<br>fsimage表示文件系统元数据镜像文件<br>NameNode在checkpoint之前首先要切换新的edits log文件，在切换时更新seen_txid的值。上次合并fsimage和editslog之后的第一个操作编号</p><p>VERSION文件是一个Java的属性文件<br>    layoutVersion是一个负数，定义了HDFS持久化数据结构的版本。这个版本数字跟hadoop发行的版本无关。当layout改变的时候，该数字减1（比如从-57到-58）。当对HDFDS进行了升级，就会发生layoutVersion的改变。<br>    namespaceID是该文件系统的唯一标志符，当NameNode第一次格式化的时候生成。<br>    clusterID是HDFS集群使用的一个唯一标志符，在HDFS联邦的情况下，就看出它的作用了，因为联邦情况下，集群有多个命名空间，不同的命名空间由不同的NameNode管理。<br>    blockpoolID是block池的唯一标志符，一个NameNode管理一个命名空间，该命名空间中的所有文件存储的block都在block池中。<br>    cTime标记着当前NameNode创建的时间。对于刚格式化的存储，该值永远是0，但是当文件系统更新的时候，这个值就会更新为一个时间戳。<br>    storageType表示当前目录存储NameNode内容的数据结构</p><p>当文件系统客户端进行了写操作（例如创建或移动了文件），这个事务首先在edits log中记录下来。NameNode在内存中有文件系统的元数据，当edits log记录结束后，就更新内存中的元数据。内存中的元数据用于响应客户端的读请求。</p><p>edits log在磁盘上表现为一定数量的文件。每个文件称为片段（Segment），前缀“edits”，后缀是其中包含的事务ID（transaction IDs）。每个写操作事务都仅仅打开一个文件（比如：edits_inprogress_00000000000010），写完后冲刷缓冲区并同步到磁盘，然后返回客户端success状态码。如果NameNode的元数据需要写到多个目录中，则对于每个写事务需要所有的写操作都完成，并冲刷缓冲区同步到磁盘才返回success状态码。这样就可以保证在发生宕机的时候没有事务数据丢失。</p><p>用户的操作是一个事务，每个操作NN都要先将操作记录到edits log中，如果给NN指定了多个目录，则在多个目录中都存在edits log文件，用户的操作要在多个目录中都写完成，才让NN同步数据到内存中。当NN在内存中也同步了数据，就返回客户端success。</p><p>每个fsimage文件都是系统元数据的一个完整的持久化检查点（checkpoint）（后缀表示镜像中的最后一个事务）。写操作不更新这个数据，因为镜像文件通常为GB数量级，写到磁盘很慢。如果NameNode宕机，可以将最新fsimage加载到内存，同时执行edits log对应于该fsimage之后的操作，就可以重建元数据的状态。而这正是每次启动NameNode的时候NameNode要做的工作。</p><h5 id="1-3-4-SecondaryNameNode"><a href="#1-3-4-SecondaryNameNode" class="headerlink" title="1.3.4    SecondaryNameNode"></a>1.3.4    SecondaryNameNode</h5><p>存在的意义<br>edits log会随着对文件系统的操作而无限制地增长，这对正在运行的NameNode而言没有任何影响，如果NameNode重启，则需要很长的时间执行edits log的记录以更新fsimage（元数据镜像文件）。在此期间，整个系统不可用。<br>在系统启动期间，NameNode合并fsimage+edits log</p><p>fsimage=0<br>edist log=很大</p><p>内存<br>fsimage=GB<br>edits log<br>内存-&gt;执行edits log条目</p><p>解决方案就是运行SecondaryNameNode，它的作用就是为NameNode内存中的文件系统元数据生成检查点（checkpoint）。fsimage</p><p><strong>工作流程</strong><br>edits_inprogress_00000000018_0000000028  seen_txid=29<br>1、secondarynamenode请求namenode生成新的edits log文件并向其中写日志。NameNode会在所有的存储目录中更新seen_txid文件<br>2、SecondaryNameNode通过HTTP GET的方式从NameNode下载fsimage和edits文件到本地。<br>3、SecondaryNameNode将fsimage加载到自己的内存，并根据edits log更新内存中的fsimage信息，然后将更新完毕之后的fsimage写到磁盘上。<br>4、SecondaryNameNode通过HTTP PUT将新的fsimage文件发送到NameNode，NameNode将该文件保存为.ckpt的临时文件备用。<br>5、NameNode重命名该临时文件并准备使用。此时NameNode拥有一个新的fsimage文件和一个新的很小的edits log文件（可能不是空的，因为在SecondaryNameNode合并期间可能对元数据进行了读写操作）。管理员也可以将NameNode置于safemode，通过hdfs dfsadmin -saveNamespace命令来进行edits log和fsimage的合并</p><p>SecondaryNameNode要和NameNode拥有相同的内存。对大的集群，SecondaryNameNode运行于一台专用的物理主机。<br><a href="https://ibb.co/m4W0VBn">图例</a></p><p>检查点创建时机<br>对于创建检查点（checkpoint）的过程，有三个参数进行配置：</p><p>1、默认情况下，SecondaryNameNode每个小时进行一次checkpoint合并<br>    由dfs.namenode.checkpoint.period设置，单位秒</p><p>2、在不足一小时的情况下，如果edits log存储的事务达到了1000000个也进行一次checkpoint合并<br>    由dfs.namenode.checkpoint.txns设置事务数量</p><p>3、事务数量检查默认每分钟进行一次<br>    由dfs.namenode.checkpoint.check.period设置，单位秒。</p><p>总结：<br>namenode<br>管理文件元数据<br>    文件名称、大小、所属关系、权限、副本大小、副本个数<br>    文件块的列表信息：(块的ID，偏移量，块的大小，块所在的主机名称列表)<br>持久化文件<br>    fsimage(内存快照)，edits log<br>    fsimage很大，GB级别；edits log只追加的文件<br>    用户操作首先记录到edits log中，然后更新内存<br>fsimage不保存数据块位置信息<br>    在系统启动的时候，datanode向namenode发送文件块列表信息（bid）<br>    datanode通过心跳向namenode汇报列表信息。<br>namenode元数据正常工作时，元数据放内存，高并发。<br>secondarynamenode<br>在系统启动的时候，namenode首先加载fsimage，然后逐条执行edits log中的日志操作，如果edits log很大，则需要很长时间才能加载完毕，向磁盘写新的fsimage，之后才可以对外提供服务。<br>周期性地从namenode拷贝fsimage+edits log，在SNN中合并为新的fsimage，推送给namenode。<br>条件：1、每小时一次，2、不足一小时，则只要edits log中记录的事务数达到了1000000，则合并。<br>datanode<br>     储存数据节点</p><p> <strong>存储结构</strong><br><a href="https://ibb.co/0M0h5mV">存储结构</a><br>1、SecondaryNameNode中checkpoint目录布局（dfs.namenode.checkpoint.dir）和NameNode中的一样。</p><p>2、如果NameNode完全坏掉（没有备用机，也没有NFS），可以快速地从SecondaryNameNode恢复。有可能丢数据</p><p>3、如果SecondaryNameNode直接接手NameNode的工作，需要在启动NameNode进程的时候添加-importCheckpoint选项。该选项会让NameNode从由dfs.namenode.checkpoint.dir属性定义的路径中加载最新的checkpoint数据，但是为了防止元数据的覆盖，要求dfs.namenode.name.dir定义的目录中没有内容。</p><h5 id="1-3-5-DataNode"><a href="#1-3-5-DataNode" class="headerlink" title="1.3.5    DataNode"></a>1.3.5    DataNode</h5><p>存储结构<br>DataNode不需要显式地格式化;关键文件和目录结构如下<br><a href="https://ibb.co/Swq7Q41">结构</a><br>1、HDFS块数据存储于blk_前缀的文件中，包含了被存储文件原始字节数据的一部分。</p><p>2、每个block文件都有一个.meta后缀的元数据文件关联。该文件包含了一个版本和类型信息的头部，后接该block中每个部分的校验和。</p><p>3、每个block属于一个block池，每个block池有自己的存储目录，该目录名称就是该池子的ID（跟NameNode的VERSION文件中记录的block池ID一样）。</p><p>当一个目录中的block达到64个（通过dfs.datanode.numblocks配置）的时候，DataNode会创建一个新的子目录来存放新的block和它们的元数据。这样即使当系统中有大量的block的时候，目录树也不会太深。同时也保证了在每个目录中文件的数量是可管理的，避免了多数操作系统都会碰到的单个目录中的文件个数限制（几十几百上千个）。</p><p>如果dfs.datanode.data.dir指定了位于在不同的硬盘驱动器上的多个不同的目录，则会通过轮询的方式向目录中写block数据。需要注意的是block的副本不会在同一个DataNode上复制，而是在不同的DataNode节点之间复制。</p><p><strong>存储数据模型(重点)</strong><br>1、文件线性切割成块（Block）（按字节切割）<br>…..<br>Hello world<br>2、Block分散存储在集群节点中<br>3、单一文件Block大小一致，文件与文件可以不一致<br>    hdfs  dfs  -D  dfs.blocksize=1048576  -D dfs.replication=2  -put hello.txt  /<br>4、Block可以设置副本数，副本分散在不同节点中<br>    a) 副本数不要超过节点数量<br>    b) 承担计算<br>    c) 容错<br>5、文件上传可以设置Block大小和副本数<br>6、已上传的文件Block副本数可以调整，大小不变<br>7、只支持一次写入多次读取，同一时刻只有一个写入者<br>    对同一个文件，一个时刻只有一个写入者<br>8、可以append追加数据</p><p>优势（了解）</p><ol><li>   一个文件的大小可以大于网络中任意一个磁盘的容量</li><li>   使用抽象块而非整个文件作为存储单元，大大简化存储子系统的设计</li><li>   块非常适合用于数据备份进而提供数据容错能力和提高可用性</li></ol><h4 id="1-4-数据块副本放置策略"><a href="#1-4-数据块副本放置策略" class="headerlink" title="1.4    数据块副本放置策略"></a>1.4    数据块副本放置策略</h4><p><a href="https://ibb.co/YWFW01M">图例</a><br>Block的副本放置策略</p><p>第一个副本：放置在上传文件的DN；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。<br>第二个副本：放置在于第一个副本不同的 机架的节点上。<br>第三个副本：与第二个副本相同机架的节点。<br>更多副本：随机节点</p><h4 id="1-5-HDFS的权限（了解）"><a href="#1-5-HDFS的权限（了解）" class="headerlink" title="1.5    HDFS的权限（了解）"></a>1.5    HDFS的权限（了解）</h4><p>1、每个文件和目录都和一个拥有者和组相关联。<br>2、文件或者目录对与拥有者、同组用户和其他用户拥有独立的权限。<br>3、对于一个文件，r表示读取的权限，w表示写或者追加的权限。对于目录而言，r表示列出目录内容的权限，w表示创建或者删除文件和目录的权限，x表示访问该目录子项目的权限。<br>4、默认情况下hadoop运行时安全措施处于停用模式。一个客户端可以在远程系统上通过创建和任意一个合法用户同名的账号来进行访问。 hadoop  root<br>5、安全措施可以防止用户或自动工具及程序意外修改或删除文件系统的重要部分。（dfs.permissions.enabled属性）。防止好人做错事。<br>6、超级用户是namenode进程的标识。对于超级用户，系统不会执行任何权限检查</p><h4 id="1-6-hadoop的安全模式"><a href="#1-6-hadoop的安全模式" class="headerlink" title="1.6    hadoop的安全模式"></a>1.6    hadoop的安全模式</h4><h5 id="1-6-1-工作流程-理解"><a href="#1-6-1-工作流程-理解" class="headerlink" title="1.6.1    工作流程(理解)"></a>1.6.1    工作流程(理解)</h5><ol><li>   启动NameNode，NameNode加载fsimage到内存，对内存数据执行edits log日志中的事务操作。</li><li>   文件系统元数据内存镜像加载完毕，进行fsimage和edits log日志的合并，并创建新的fsimage文件和一个空的edits log日志文件。</li><li>   NameNode等待DataNode上传block列表信息，直到副本数满足最小副本条件。</li><li>   当满足了最小副本条件，再过30秒，NameNode就会退出安全模式。最小副本条件指整个文件系统中有99.9%的block达到了最小副本数（默认值是1，可设置）</li></ol><p>在NameNode安全模式（safemode）</p><ol><li>   对文件系统元数据进行只读操作</li><li>   当文件的所有block信息具备的情况下，对文件进行只读操作</li><li>   不允许进行文件修改（写，删除或重命名文件）</li></ol><h5 id="1-6-2-注意事项"><a href="#1-6-2-注意事项" class="headerlink" title="1.6.2    注意事项"></a>1.6.2    注意事项</h5><ol><li>   NameNode不会持久化block位置信息；DataNode保有各自存储的block列表信息。正常操作时，NameNode在内存中有一个block位置的映射信息。</li><li>   NameNode在安全模式，NameNode需要给DataNode时间来上传block列表信息到NameNode。如果NameNode不等待DataNode上传这些信息的话，则会在DataNode之间进行block的复制，而这在大多数情况下都是非必须的（因为只需要等待DataNode上传就行了），还会造成资源浪费。</li><li>   在安全模式NameNode不会要求DataNode复制或删除block。</li><li>   新格式化的HDFS不进入安全模式，因为DataNode压根就没有block。</li></ol><h4 id="1-6-4-命令操作-了解"><a href="#1-6-4-命令操作-了解" class="headerlink" title="1.6.4    命令操作(了解)"></a>1.6.4    命令操作(了解)</h4><p>通过命令查看namenode是否处于安全模式：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ hdfs dfsadmin -safemode getSafe mode is ON<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>HDFS的前端webUI页面也可以查看NameNode是否处于安全模式。<br>有时候我们希望等待安全模式退出，之后进行文件的读写操作，尤其是在脚本中，此时：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ hdfs dfsadmin -safemode wait# your read or write command goes here<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>管理员有权在任何时间让namenode进入或退出安全模式。进入安全模式：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ hdfs dfsadmin -safemode enterSafe mode is ON<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这样做可以让namenode一直处于安全模式，也可以设置dfs.namenode.safemode.threshold-pct为1做到这一点。<br>离开安全模式：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ hdfs dfsadmin -safemode leaveSafe mode is OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="1-7-HDFS写文件流程（重点）"><a href="#1-7-HDFS写文件流程（重点）" class="headerlink" title="1.7    HDFS写文件流程（重点）"></a>1.7    HDFS写文件流程（重点）</h4><h5 id="1-7-1-流程"><a href="#1-7-1-流程" class="headerlink" title="1.7.1    流程"></a>1.7.1    流程</h5><p><a href="https://ibb.co/K25Y9Pm">流程</a></p><ol><li>   调用客户端的对象DistributedFileSystem的create方法；</li><li>   DistributedFileSystem会发起对namenode的一个RPC连接，请求创建一个文件，不包含关于block块的请求。namenode会执行各种各样的检查，确保要创建的文件不存在，并且客户端有创建文件的权限。如果检查通过，namenode会创建一个文件（在edits中，同时更新内存状态），否则创建失败，客户端抛异常IOException。</li><li>   DistributedFileSystem返回一个FSDataOutputStream对象给客户端用于写数据。FSDataOutputStream封装了一个DFSOutputStream对象负责客户端跟datanode以及namenode的通信。</li><li>   FSDataOutputStream对象将数据切分为小的数据包（64kb，core-default.xml：file.client-write-packet-size默认值65536），并写入到一个内部队列（“数据队列”）。DataStreamer会读取其中内容，并请求namenode返回一个datanode列表来存储当前block副本。列表中的datanode会形成管线，DataStreamer将数据包发送给管线中的第一个datanode，第一个datanode将接收到的数据发送给第二个datanode，第二个发送给第三个。。。</li><li>   DFSOoutputStream维护着一个数据包的队列，这的数据包是需要写入到datanode中的，该队列称为确认队列。当一个数据包在管线中所有datanode中写入完成，就从ack队列中移除该数据包。如果在数据写入期间datanode发生故障，则执行以下操作<br>a)    关闭管线，把确认队列中的所有包都添加回数据队列的最前端，以保证故障节点下游的datanode不会漏掉任何一个数据包。<br>b)    为存储在另一正常datanode的当前数据块指定一个新的标志，并将该标志传送给namenode，以便故障datanode在恢复后可以删除存储的部分数据块。<br>c)    从管线中删除故障数据节点并且把余下的数据块写入管线中另外两个正常的datanode。namenode在检测到副本数量不足时，会在另一个节点上创建新的副本。<br>d)    后续的数据块继续正常接受处理。<br>e)    在一个块被写入期间可能会有多个datanode同时发生故障，但非常少见。只要设置了dfs.replication.min的副本数（默认为1），写操作就会成功，并且这个块可以在集群中异步复制，直到达到其目标副本数（dfs.replication默认值为3）。</li><li>   如果有多个block，则会反复从步骤4开始执行。</li><li>   当客户端完成了数据的传输，调用数据流的close方法。该方法将数据队列中的剩余数据包写到datanode的管线并等待管线的确认</li><li>   客户端收到管线中所有正常datanode的确认消息后，通知namenode文件写完了。</li><li>   namenode已经知道文件由哪些块组成，所以它在返回成功前只需要等待数据块进行最小量的复制。</li></ol><h4 id="1-8-HDFS读文件流程（重点）"><a href="#1-8-HDFS读文件流程（重点）" class="headerlink" title="1.8    HDFS读文件流程（重点）"></a>1.8    HDFS读文件流程（重点）</h4><h5 id="1-8-1-流程"><a href="#1-8-1-流程" class="headerlink" title="1.8.1    流程"></a>1.8.1    流程</h5><p><a href="https://ibb.co/t393fxJ">流程</a></p><ol><li>   客户端通过FileSystem对象的open方法打开希望读取的文件，DistributedFileSystem对象通过RPC调用namenode，以确保文件起始位置。对于每个block，namenode返回存有该副本的datanode地址。这些datanode根据它们与客户端的距离来排序。如果客户端本身就是一个datanode，并保存有相应block一个副本，会从本地读取这个block数据。</li><li>   DistributedFileSystem返回一个FSDataInputStream对象给客户端读取数据。该类封装了DFSInputStream对象，该对象管理着datanode和namenode的I/O，用于给客户端使用。客户端对这个输入调用read方法，存储着文件起始几个block的datanode地址的DFSInputStream连接距离最近的datanode。通过对数据流反复调用read方法，可以将数据从datnaode传输到客户端。到达block的末端时，DFSInputSream关闭与该datanode的连接，然后寻找下一个block的最佳datanode。客户端只需要读取连续的流，并且对于客户端都是透明的。</li><li>   客户端从流中读取数据时，block是按照打开DFSInputStream与datanode新建连接的顺序读取的。它也会根据需要询问namenode来检索下一批数据块的datanode的位置。一旦客户端完成读取，就close掉FSDataInputStream的输入流。</li><li>   在读取数据的时候如果DFSInputStream在与datanode通信时遇到错误，会尝试从这个块的一个最近邻datanode读取数据。它也记住那个故障datanode，保证以后不会反复读取该节点上后续的block。DFSInputStream也会通过校验和确认从datanode发来的数据是否完整。如果发现有损坏的块，就在DFSInputStream试图从其他datanode读取其副本之前通知namenode。</li><li>   Client下载完block后会验证DN中的MD5，保证块数据的完整性。</li></ol><h5 id="1-8-2-注意"><a href="#1-8-2-注意" class="headerlink" title="1.8.2    注意"></a>1.8.2    注意</h5><p>namenode告知客户端每个block中最佳的datanode，并让客户端<strong>直接</strong>连到datanode检索数据。由于数据流分散在集群中的所有datanode，这样可以使HDFS可扩展到大量的并发客户端。同时，namenode只需要响应block位置的请求，无需响应数据请求，否则namenode会成为瓶颈。</p><h5 id="1-8-3-最近邻（了解）"><a href="#1-8-3-最近邻（了解）" class="headerlink" title="1.8.3    最近邻（了解）"></a>1.8.3    最近邻（了解）</h5><p>hadoop把网络看作是一棵树，两个节点间的距离是它们到最近共同祖先的距离和。通常可以设置等级：</p><ol><li>   同一个节点上的进程</li><li>   同一机架上的不同节点</li><li>   同一数据中心中不同机架上的节点</li><li>   不同数据中心中的节点</li></ol><h4 id="1-9-伪分布式搭建"><a href="#1-9-伪分布式搭建" class="headerlink" title="1.9    伪分布式搭建"></a>1.9    伪分布式搭建</h4><p><a href="http://hadoop.apache.org/">hadoop官网地址</a><br><a href="http://hadoop.apache.org/docs/r1.0.4/cn">中文文档</a><br>安装&amp;部署:<br>node1:        NN        DN        SNN<br>1)基础设施<br>        GUN/Linux<br>        jdk  1.7+<br>        环境:JAVA_HOME -&gt;  /etc/profile   ~/.bash_profile<br>        ssh免密:<br>            远程执行&lt;-不需要用户交互,而是用户直接给出一个命令,直接在远程执行<br>                    不会加载 /etc/profile<br>            远程登陆&lt;-返回一个交互接口<br>                    返回接口/bash  会加载/etc/profile<br>            ip<br>            时间同步<br>            hosts/hostname<br>2)应用的安装<br>            a)绿色:开箱即用(配置/部署)<br>                环境变量<br>                应用自己的环境变量<br>                JAVA_HOME -&gt;  hadoop-env.sh<br>            b)操作:<br>                format<br>                start<br>                使用</p><h5 id="1-9-1-上传hadoop的tar包和jdk的rpm包"><a href="#1-9-1-上传hadoop的tar包和jdk的rpm包" class="headerlink" title="1.9.1    上传hadoop的tar包和jdk的rpm包"></a>1.9.1    上传hadoop的tar包和jdk的rpm包</h5><p>hadoop-2.6.5.tar.gz<br>jdkxxx.rpm<br>将文件上传到/opt/apps目录下</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 apps]# tar -zxvf hadoop-2.6.5.tar.gz -C &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-9-2-安装jdk并配置环境变量"><a href="#1-9-2-安装jdk并配置环境变量" class="headerlink" title="1.9.2    安装jdk并配置环境变量"></a>1.9.2    安装jdk并配置环境变量</h5><pre class="line-numbers language-linux" data-language="linux"><code class="language-linux">[root@node1 apps]# rpm -ivh jdk-8u221-linux-x64.rpm[root@node1 apps]# vim  &#x2F;etc&#x2F;profileexport  JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;defaultexport  PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin[root@node1 apps]# source  &#x2F;etc&#x2F;profile  或者  .  &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="1-9-3-配置免密钥"><a href="#1-9-3-配置免密钥" class="headerlink" title="1.9.3    配置免密钥"></a>1.9.3    配置免密钥</h5><pre class="line-numbers language-linux" data-language="linux"><code class="language-linux">tar  -zxf  hadoop-2.6.5.tar.gz  -C  &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-9-4-解压hadoop-2-6-5-tar-gz到-opt目录"><a href="#1-9-4-解压hadoop-2-6-5-tar-gz到-opt目录" class="headerlink" title="1.9.4    解压hadoop-2.6.5.tar.gz到/opt目录"></a>1.9.4    解压hadoop-2.6.5.tar.gz到/opt目录</h5><pre class="line-numbers language-linux" data-language="linux"><code class="language-linux">tar  -zxf  hadoop-2.6.5.tar.gz  -C  &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-9-5-添加环境变量"><a href="#1-9-5-添加环境变量" class="headerlink" title="1.9.5    添加环境变量"></a>1.9.5    添加环境变量</h5><p>将HADOOP_HOME以及HADOOP_HOME/bin和HADOOP_HOME/sbin添加到环境变量</p><pre class="line-numbers language-sheel" data-language="sheel"><code class="language-sheel">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.6.5export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="1-9-6-hadoop-env-sh配置"><a href="#1-9-6-hadoop-env-sh配置" class="headerlink" title="1.9.6    hadoop-env.sh配置"></a>1.9.6    hadoop-env.sh配置</h5><p>$HADOOP_HOME/etc/hadoop<br>由于通过SSH远程启动进程的时候默认不会加载/etc/profile设置，JAVA_HOME变量就加载不到，需要手动指定。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_221-amd64#或export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;default<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="1-9-7-core-site-xml"><a href="#1-9-7-core-site-xml" class="headerlink" title="1.9.7    core-site.xml"></a>1.9.7    core-site.xml</h5><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定访问HDFS的时候路径的默认前缀  /  hdfs://node1:9000/ --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node1:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定hadoop的临时目录位置，它会给namenode、secondarynamenode以及datanode的存储目录指定前缀 --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/var/bjsxt/hadoop/pseudo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>配置文件拷贝后格式不美观，可以通过以下方式格式化：</p><ol><li>   拷贝到对应的文件</li><li>Esc-&gt;Ctrl+V (下箭头选择要格式化的代码）<br> :!xmllint -format -<br> dd:再删除多没有&lt;?xml ….&gt;</li><li>   拷贝格式化后的代码，然后回车</li><li>   dG删除非格式的代码</li><li>   i-&gt;Shift+Ins将格式后的内容拷贝到文件中</li><li>   保存并退出</li></ol><h5 id="1-9-8-hdfs-site-xml"><a href="#1-9-8-hdfs-site-xml" class="headerlink" title="1.9.8    hdfs-site.xml"></a>1.9.8    hdfs-site.xml</h5><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定block副本数 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1：：<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定secondarynamenode所在的位置 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node1:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="1-9-9-slaves"><a href="#1-9-9-slaves" class="headerlink" title="1.9.9    slaves"></a>1.9.9    slaves</h5><p>DataNode所在的节点</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@bk1 hadoop]# vim slavesnode1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="1-9-10-格式化"><a href="#1-9-10-格式化" class="headerlink" title="1.9.10    格式化"></a>1.9.10    格式化</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs  namenode  -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-9-11-启动"><a href="#1-9-11-启动" class="headerlink" title="1.9.11    启动"></a>1.9.11    启动</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-9-12-查看进程"><a href="#1-9-12-查看进程" class="headerlink" title="1.9.12    查看进程"></a>1.9.12    查看进程</h5><pre class="line-numbers language-linux" data-language="linux"><code class="language-linux">[root@node1 current]# jps1943 SecondaryNameNode1800 DataNode1693 NameNode2045 Jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>说明进程都正常启动了，然后网页访问：<a href="http://node1:50070/">http://node1:50070</a></p><h5 id="1-9-13-上传文件"><a href="#1-9-13-上传文件" class="headerlink" title="1.9.13    上传文件"></a>1.9.13    上传文件</h5><p>生成本地文件：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">for i in &#96;seq 100000&#96;; do echo &quot;hello bjsxt $i&quot; &gt;&gt; hh.txt; donell -hhdfs dfs -D dfs.blocksize&#x3D;1048576 -D dfs.replication&#x3D;1 -put hh.txt &#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="1-9-14-关闭"><a href="#1-9-14-关闭" class="headerlink" title="1.9.14    关闭"></a>1.9.14    关闭</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 ~]# stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-HDFS搭建"><a href="#2-HDFS搭建" class="headerlink" title="2 HDFS搭建"></a>2 HDFS搭建</h3><p>####1.1 目标<br>HDFS完全分布式搭建(熟练)<br>Hadoop 3.x 新特性（了解）<br>Hadoop Federation（了解）<br>Hadoop HA（掌握）<br>Hadoop HA 集群搭建（熟练）<br>java客户端操作HDFS（熟练）</p><h4 id="1-2-HDFS完全分布式搭建"><a href="#1-2-HDFS完全分布式搭建" class="headerlink" title="1.2    HDFS完全分布式搭建"></a>1.2    HDFS完全分布式搭建</h4><h5 id="1-2-1-规划"><a href="#1-2-1-规划" class="headerlink" title="1.2.1    规划"></a>1.2.1    规划</h5><p>四台服务器：<br>| node | node2 | node3 | node4 |<br>| – | – | – | – |<br>| NameNode | SecondaryNameNode |  |  |<br>| | DataNode-1 | DataNode-2 | DataNode -3 |</p><ol><li>基础设置<br> a)    网络<br> b)    Ssh: 哪个节点将公钥分发,成为启动start-dfs.sh脚本的主机和这个主机上的进程没有关系<br> c)    Jdk</li><li>应用搭建<br> a)    部署&amp;配置<br> b)    执行:</li></ol><h5 id="1-2-2-搭建步骤"><a href="#1-2-2-搭建步骤" class="headerlink" title="1.2.2    搭建步骤"></a>1.2.2    搭建步骤</h5><h6 id="1-2-2-1-免密钥设置"><a href="#1-2-2-1-免密钥设置" class="headerlink" title="1.2.2.1    免密钥设置"></a>1.2.2.1    免密钥设置</h6><p>四台服务器之间互相均可以免密登录<br>a、    首先在四台服务器上都要执行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ssh-keygen  -t  dsa  -P  &#39;&#39;  -f  ~&#x2F;.ssh&#x2F;id_dsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>b、在node1上将node1 的公钥拷贝到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  将该文件拷贝给node2：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node2:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c、在node2中将node2的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>   将该文件拷贝给node3：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>d、在node3中将node3的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将该文件拷贝给node4：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node4:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>e、在node4中将node4的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将该文件拷贝给node1、node2、node3：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node1:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node2:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h6 id="1-2-2-2-JDK安装环境变量配置"><a href="#1-2-2-2-JDK安装环境变量配置" class="headerlink" title="1.2.2.2    JDK安装环境变量配置"></a>1.2.2.2    JDK安装环境变量配置</h6><p>首先将node1中的hadoop-2.6.5删除，或者通过快照还原到单机伪分布安装前的环境。<br>node1-node4</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir &#x2F;opt&#x2F;apps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将jdk-8u221-linux-x64.rpm上传到node1/opt/apps<br>将/opt/apps下的jdk.rpm scp到node2、node3、node4的对应目录中</p><pre class="line-numbers language-none"><code class="language-none">scp jdk-8u221-linux-x64.rpm node2:&#96;pwd&#96;scp jdk-8u221-linux-x64.rpm node3:&#96;pwd&#96;scp jdk-8u221-linux-x64.rpm node4:&#96;pwd&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在node1、node2、node3、node4上安装jdk并配置profile文件</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">rpm -ivh jdk-8u221-linux-x64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将hadoop安装文件上传到node1的/opt/apps目录下，并解压到/opt目录下</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar  -zxvf  hadoop-2.6.5.tar.gz  -C  &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>node1上修改环境变量</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.6.5export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Node2上修改环境变量：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.6.5exportPATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$ZOOKEEPER_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>让配置文件生效</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">source &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将node2的/etc/profile拷贝到node3、node4上并执行. /etc/profile</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp &#x2F;etc&#x2F;profile node[34]:&#96;pwd&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h6 id="1-2-2-3-Hadoop相关配置"><a href="#1-2-2-3-Hadoop相关配置" class="headerlink" title="1.2.2.3    Hadoop相关配置"></a>1.2.2.3    Hadoop相关配置</h6><p>先在node1上配置好，然后将之scp到node2-node4上</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;opt&#x2F;hadoop-2.6.5&#x2F;etc&#x2F;hadoop&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol><li><p>   hadoop-env.sh配置<br>$HADOOP_HOME/etc/hadoop<br>由于通过SSH远程启动进程的时候默认不会加载/etc/profile设置，JAVA_HOME变量就加载不到，需要手动指定。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export  JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_221-amd64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>   修改slaves指定datanode的位置</p><pre class="line-numbers language-none"><code class="language-none">node2node3node4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>   修改hdfs-site.xml<br>指定SNN的位置</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>   修改core-site.xml</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!--用来指定hdfs的老大，namenode的地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node1:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定hadoop的临时目录位置--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/var/bjsxt/hadoop/full<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>   拷贝到node2-node4上<br>先将之打成压缩包</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 opt]# tar -zcvf hadoop-2.6.5.tar.gz hadoop-2.6.5&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>将/opt/hadoop-2.6.5.tar.gz scp到node2、node3、node4的对应目录中</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  hadoop-2.6.5.tar.gz node2:&#x2F;optscp  hadoop-2.6.5.tar.gz node3:&#x2F;optscp  hadoop-2.6.5.tar.gz node4:&#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>node2、node3、node4分别解压</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 opt]# tar -zxvf hadoop-2.6.5.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h6 id="1-2-2-4-格式化并启动"><a href="#1-2-2-4-格式化并启动" class="headerlink" title="1.2.2.4    格式化并启动"></a>1.2.2.4    格式化并启动</h6><p>格式化<br>在node1上执行：</p><pre class="line-numbers language-none"><code class="language-none">hdfs  namenode  -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动即可(该命令在四台服务器上哪一台执行都可以)</p><pre class="line-numbers language-none"><code class="language-none">start-dfs.shhttp:&#x2F;&#x2F;192.168.20.201:50070[root@node1 opt]#hdfs dfs -mkdir -p &#x2F;user&#x2F;root[root@node1 opt]# hdfs dfs -put hadoop-2.6.5.tar.gz &#x2F;user&#x2F;root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h6 id="1-2-2-5-停止"><a href="#1-2-2-5-停止" class="headerlink" title="1.2.2.5    停止"></a>1.2.2.5    停止</h6><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-3-Hadoop-Federation（了解）联邦"><a href="#1-3-Hadoop-Federation（了解）联邦" class="headerlink" title="1.3    Hadoop Federation（了解）联邦"></a>1.3    Hadoop Federation（了解）联邦</h4><h5 id="1-3-1-NameNode需要多少内存"><a href="#1-3-1-NameNode需要多少内存" class="headerlink" title="1.3.1    NameNode需要多少内存"></a>1.3.1    NameNode需要多少内存</h5><p>问题：NameNode需要多大的内存？<br>业界看法：1GB内存放1，000，000block元数据<br>200个节点的集群中每个节点有24TB存储空间，block大小为128MB，block复制因子为3，能存储大概12500,000个block（或更多）：200×24,000,000MB/(128MB×3)。此时，NameNode内存大概需要12.5GB。</p><h5 id="1-3-2-HDFS组成"><a href="#1-3-2-HDFS组成" class="headerlink" title="1.3.2    HDFS组成"></a>1.3.2    HDFS组成</h5><p>1、Namespace<br>    a) 包括目录，文件和block块。<br>    b) 支持所有跟文件系统命名空间相关的操作<br>    如：创建、删除、修改和列出文件及目录。<br>2、Block存储服务包含两部分：<br>    a) NameNode中的block块管理<br>        i. 通过心跳机制和注册机制提供了对DataNode集群的管理。<br>        ii. 处理block块报告，管理block块的位置。<br>        iii. 提供跟block块相关的操作，如：创建、修改、删除和查询block块的位置。<br>        iv. 管理block副本如何放置，当副本数少于指定值之后增加副本，当副本数多于指定值之后删除副本。<br>    b) 存储：<br>        在DataNode本地文件系统中存储block块，并提供读/写访问。<br><a href="https://ibb.co/3kpShZW">图例</a></p><p>1、NameNode节点之间是相互独立的联邦的关系，即它们之间不需要协调服务。<br>2、DataNode向集群中所有的NameNode注册，发送心跳和block块列表报告，处理来自NameNode的指令。<br>3、用户可以使用ViewFs创建个性化的命名空间视图，ViewFs类似于在Unix/Linux系统中的客户端挂载表。</p><p><strong>VERSION</strong><br>namespaceID  用于标记namenode的ID<br>blockpoolID  用于标记block存储池子的ID<br>clusterID  集群的ID</p><p><strong>Hadoop-env.sh</strong><br>配置JAVA_HOME<br><strong>core-site.xml配置：</strong></p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>viewfs://ClusterX<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.viewfs.mounttable.ClusterX.link./data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node1:8020/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.viewfs.mounttable.ClusterX.link./project<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node1:8020/project<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.viewfs.mounttable.ClusterX.link./user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node2:8020/user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.viewfs.mounttable.ClusterX.link./tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node2:8020/tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.viewfs.mounttable.ClusterX.linkFallback<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node2:8020/home<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/var/bjsxt/hadoop/federation<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>hdfs-site.xml</strong></p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.blocksize<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1048576<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.nameservices<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>ns1,ns2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.rpc-address.ns1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node1:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.http-address.ns1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node1:50070<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address.ns1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node3:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.rpc-address.ns2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.http-address.ns2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:50070<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address.ns2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node4:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>slaves<br>node2<br>node3<br>node4</p><p>格式化node1</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$HADOOP_PREFIX_HOME&#x2F;bin&#x2F;hdfs namenode -format -clusterId myviewfs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>格式化node2</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$HADOOP_PREFIX_HOME&#x2F;bin&#x2F;hdfs namenode -format -clusterId myviewfs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在格式化node1和node2上的namenode时候，需要指定clusterId，并且两个格式化的时候这个clusterId要一致，两个namenode具有相同的clusterId，它们在一个集群中，它们是联邦的关系<br>启动</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>配置</p><pre class="line-numbers language-hadoop" data-language="hadoop"><code class="language-hadoop">hdfs dfs -mkdir hdfs:&#x2F;&#x2F;node1:8020&#x2F;datahdfs dfs -mkdir hdfs:&#x2F;&#x2F;node1:8020&#x2F;projecthdfs dfs -mkdir hdfs:&#x2F;&#x2F;node2:8020&#x2F;userhdfs dfs -mkdir hdfs:&#x2F;&#x2F;node2:8020&#x2F;tmphdfs dfs -mkdir hdfs:&#x2F;&#x2F;node2:8020&#x2F;home<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>停止</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-3-3-优点"><a href="#1-3-3-优点" class="headerlink" title="1.3.3    优点"></a>1.3.3    优点</h5><p>1、    通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使得namenode/namespace可以通过增加机器来进行水平扩展。<br>2、    能把单个namenode的负载分散到多个节点中，在HDFS数据规模较大的时候不会也降低HDFS的性能。<br>3、    可以通过多个namespace来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中</p><h4 id="1-4-Hadoop-NameNode-HA"><a href="#1-4-Hadoop-NameNode-HA" class="headerlink" title="1.4    Hadoop NameNode HA"></a>1.4    Hadoop NameNode HA</h4><p>HDFS  2.x<br>解决HDFS 1.0中单点故障和内存受限问题，联邦     HA<br>HDFS2.x中Federation和HA分离，HA只能有两个NameNode<br><strong>解决单点故障</strong><br>HDFS HA：通过主备NameNode解决<br>如果主NameNode发生故障，则切换到备NameNode上。<br><strong>解决内存受限问题</strong><br>HDFS Federation(联邦)；水平扩展，支持多个NameNode；<br>（1）所有NameNode共享所有DataNode存储资源<br>（2）每个NameNode分管一部分目录</p><h5 id="1-4-1-手动HA"><a href="#1-4-1-手动HA" class="headerlink" title="1.4.1    手动HA"></a>1.4.1    手动HA</h5><p>fsimage+edits log需要<br><a href="https://ibb.co/b2cg9Gh">图例</a><br>由StandbyNameNode做合并工作<br>fsimage推送的时机可以通过参数来调整：<br>dfs.namenode.checkpoint.period    1小时<br>dfs.namenode.checkpoint.txns      100 0000事务<br>dfs.namenode.checkpoint.check.period   3s<br>dfs.namenode.num.checkpoints.retained<br>dfs.ha.tail-edits.period</p><p>1、    一个NameNode进程处于Active状态，另1个NameNode进程处于Standby状态。Active的NameNode负责处理客户端的请求。<br>2、    Active的NN修改了元数据之后，会在JNs的半数以上的节点上记录这个日志。Standby状态的NameNode会监视任何对JNs上edit log的更改。一旦edits log出现更改，Standby的NN就会根据edits log更改自己记录的元数据。<br>3、    当发生故障转移时，Standby主机会确保已经读取了JNs上所有的更改来同步它本身记录的元数据，然后由Standby状态切换为Active状态。<br>4、    为了确保在发生故障转移操作时拥有相同的数据块位置信息，DNs向所有NN发送数据块位置信息和心跳数据。<br>5、    JNs只允许一台NameNode向JNs写edits log数据，这样就能保证不会发生“脑裂</p><h5 id="1-4-2-自动HA"><a href="#1-4-2-自动HA" class="headerlink" title="1.4.2    自动HA"></a>1.4.2    自动HA</h5><p><a href="https://ibb.co/mJLWCJK">图例</a></p><h5 id="1-4-3-总结"><a href="#1-4-3-总结" class="headerlink" title="1.4.3    总结"></a>1.4.3    总结</h5><p>主备NameNode<br>解决单点故障（属性，位置）元数据<br>主NameNode对外提供服务，备NameNode同步主NameNode元数据，以待切换<br>所有DataNode同时向两个NameNode汇报数据块信息（位置）<br>JNN:集群（属性）同步edits log<br>standby：备，完成了edits.log文件的合并产生新的image，推送回ANN<br><strong>两种切换选择</strong><br>手动切换：通过命令实现主备之间的切换，可以用HDFS升级等场合<br>自动切换：基于Zookeeper实现<br><strong>基于Zookeeper自动切换方案</strong><br>    ZooKeeper Failover Controller：监控NameNode健康状态，并向Zookeeper注册NameNode。NameNode挂掉后，ZKFC为NameNode竞争锁，获得ZKFC 锁的NameNode变为active<br>zookeeper的分布式锁，keepalived</p><h3 id="1-5-Hadoop-HA-集群搭建"><a href="#1-5-Hadoop-HA-集群搭建" class="headerlink" title="1.5    Hadoop HA 集群搭建"></a>1.5    Hadoop HA 集群搭建</h3><h4 id="1-5-1-规划"><a href="#1-5-1-规划" class="headerlink" title="1.5.1    规划"></a>1.5.1    规划</h4><p>略》》 </p><h4 id="1-5-2-搭建步骤"><a href="#1-5-2-搭建步骤" class="headerlink" title="1.5.2    搭建步骤"></a>1.5.2    搭建步骤</h4><p><a href="https://ibb.co/mttQpW2">图例</a><br>如何让ssh不提示fingerprint信息，然后输入yes或者no<br>/etc/ssh/ssh_config(客户端配置文件)  区别于sshd_config(服务端配置文件)</p><p> <a href="https://ibb.co/wcW30sq">配置文件</a></p><h6 id="1-5-2-1-四台服务器之间免密登录"><a href="#1-5-2-1-四台服务器之间免密登录" class="headerlink" title="1.5.2.1    四台服务器之间免密登录"></a>1.5.2.1    四台服务器之间免密登录</h6><p> 四台服务器之间互相均可以免密登录<br>a、    首先在四台服务器上都要执行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ssh-keygen  -t  dsa  -P  &#39;&#39;  -f  ~&#x2F;.ssh&#x2F;id_dsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>b、在node1上将node1 的公钥拷贝到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>#将该文件拷贝给node2：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node2:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c、在node2中将node2的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys#将该文件拷贝给node3：scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>d、在node3中将node3的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys#将该文件拷贝给node4：scp  ~&#x2F;.ssh&#x2F;authorized_keys   node4:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>e、在node4中将node4的公钥追加到authorized_keys中：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys#将该文件拷贝给node1、node2、node3：scp  ~&#x2F;.ssh&#x2F;authorized_keys   node1:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node2:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="1-5-2-2-JDK安装环境变量配置"><a href="#1-5-2-2-JDK安装环境变量配置" class="headerlink" title="1.5.2.2    JDK安装环境变量配置"></a>1.5.2.2    JDK安装环境变量配置</h6><p>首先将node1中的hadoop-2.6.5删除，或者通过快照还原到单机伪分布安装前的环境。<br>node1-node4</p><pre class="line-numbers language-none"><code class="language-none">mkdir &#x2F;opt&#x2F;apps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将jdk-8u221-linux-x64.rpm上传到node1/opt/apps<br>将/opt/apps下的jdk.rpm scp到node2、node3、node4的对应目录中</p><pre class="line-numbers language-none"><code class="language-none">scp jdk-8u221-linux-x64.rpm node2:&#x2F;opt&#x2F;appsscp jdk-8u221-linux-x64.rpm node3:&#x2F;opt&#x2F;appsscp jdk-8u221-linux-x64.rpm node4:&#x2F;opt&#x2F;apps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在node1、node2、node3、node4上安装jdk并配置profile文件</p><pre class="line-numbers language-none"><code class="language-none">rpm -ivh jdk-8u221-linux-x64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>node1上修改环境变量</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">vim &#x2F;etc&#x2F;profileexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;defaultexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>将node1的/etc/profile拷贝到node2、node3、node4上并执行. /etc/profile</p><pre class="line-numbers language-none"><code class="language-none">scp &#x2F;etc&#x2F;profile node[234]:&#96;pwd&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h6 id="1-5-2-3-zookeeper集群搭建"><a href="#1-5-2-3-zookeeper集群搭建" class="headerlink" title="1.5.2.3    zookeeper集群搭建"></a>1.5.2.3    zookeeper集群搭建</h6><p>a) 将zookeeper.tar.gz上传到node2<br>b) 解压到/opt</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar -zxvf zookeeper-3.4.6.tar.gz -C &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c) 配置环境变量：</p><pre class="line-numbers language-none"><code class="language-none">export ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.6export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$ZOOKEEPER_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后./etc/profile让配置生效<br> 最后将该文件scp到node3和node4上，并分别./etc/profile让配置生效.</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp &#x2F;etc&#x2F;profile bk3:&#x2F;etc&#x2F;scp &#x2F;etc&#x2F;profile bk4:&#x2F;etc&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>d) 到$ZOOKEEPER_PREFIX/conf下<br>复制zoo_sample.cfg为zoo.cfg</p><pre class="line-numbers language-none"><code class="language-none">cp zoo_sample.cfg  zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>e) 编辑zoo.cfg<br>添加如下行：<br>server.1=node2:2881:3881<br>server.2=node3:2881:3881<br>server.3=node4:2881:3881</p><p>修改<br>dataDir=/var/bjsxt/zookeeper/data</p><p>f) 创建/var/bjsxt/zookeeper/data目录，并在该目录下放一个文件：myid<br>在myid中写下当前zookeeper的编号</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;dataecho 1 &gt; &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;data&#x2F;myid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>g)将配置好zookeeper拷贝到node3、node4上</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp -r zookeeper-3.4.6&#x2F; bk3:&#x2F;opt&#x2F;scp -r zookeeper-3.4.6&#x2F; bk4:&#x2F;opt&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>h) 在node3和node4上分别创建/var/bjsxt/zookeeper/data目录，<br>并在该目录下放一个文件：myid</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">node3mkdir -p &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;dataecho 2 &gt; &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;data&#x2F;myidnode4mkdir -p &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;dataecho 3 &gt; &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;data&#x2F;myid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>i) 分别启动zookeeper<br>        zkServer.sh start 启动zk<br>        zkServer.sh stop  停止zk<br>        zkServer.sh status  查看zk状态<br>        zkServer.sh start|stop|status<br>j) 关闭zookeeper<br>        zkServer.sh stop<br>l) 连接zookeeper<br>        zkCli.sh     node2、node3、node4都可以<br>m) 退出zkCli.sh命令<br>        quit</p><h6 id="1-5-2-4-hadoop配置"><a href="#1-5-2-4-hadoop配置" class="headerlink" title="1.5.2.4    hadoop配置"></a>1.5.2.4    hadoop配置</h6><p><strong>一律在node1上操作，做完后scp到node2、node3、node4</strong></p><ol><li><p>   hadoop-env.sh配置JDK</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;default<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>core-site.xml</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://mycluster<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/var/bjsxt/hadoop/ha<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定每个zookeeper服务器的位置和客户端端口号 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>ha.zookeeper.quorum<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:2181,node3:2181,node4:2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>   hdfs-site.xml</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定副本的数量 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 解析参数dfs.nameservices值hdfs://mycluster的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.nameservices<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mycluster<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- mycluster由以下两个namenode支撑 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.ha.namenodes.mycluster<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>nn1,nn2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定nn1地址和端口号  --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.rpc-address.mycluster.nn1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node1:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定nn2地址和端口号  --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.rpc-address.mycluster.nn2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定客户端查找active的namenode的策略：                会给所有namenode发请求，以决定哪个是active的 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.client.failover.proxy.provider.mycluster<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 指定三台journal node服务器的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.shared.edits.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>qjournal://node1:8485;node2:8485;node3:8485/mycluster<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.journalnode.edits.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/var/bjsxt/hadoop/ha/jnn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!-- 当active nn出现故障时，ssh到对应的服务器，将namenode进程kill掉  --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.ha.fencing.methods<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>sshfence<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.ha.fencing.ssh.private-key-files<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/root/.ssh/id_dsa<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment">&lt;!--启动NN故障自动切换 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.ha.automatic-failover.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>   修改slaves指定datanode的位置</p><pre class="line-numbers language-none"><code class="language-none">[root@node1 hadoop]# vim slavesnode2node3node4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>   先同步配置文件到node2、node3、node4<br>node1上执行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 opt]# tar -zcvf hadoop-2.6.5.tar.gz hadoop-2.6.5&#x2F;[root@node1 opt]# scp hadoop-2.6.5.tar.gz node2:&#x2F;opt&#x2F;apps&#x2F;[root@node1 opt]# scp hadoop-2.6.5.tar.gz node3:&#x2F;opt&#x2F;apps&#x2F;  [root@node1 opt]# scp hadoop-2.6.5.tar.gz node4:&#x2F;opt&#x2F;apps&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>node2、node3、node4分别执行解压：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar -zxvf &#x2F;opt&#x2F;apps&#x2F;hadoop-2.6.5.tar.gz  -C &#x2F;opt&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Hadoop环境变量配置：<br>node1上：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 opt]# vim &#x2F;etc&#x2F;profileexport HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.6.5export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>node2上：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 opt]# vim &#x2F;etc&#x2F;profileexport ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.6export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-2.6.5export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$ZOOKEEPER_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin[root@node1 opt]#source &#x2F;etc&#x2F;profile  [root@node1 opt]# scp &#x2F;etc&#x2F;profile bk3:&#x2F;etc&#x2F;   [root@node1 opt]# scp &#x2F;etc&#x2F;profile bk4:&#x2F;etc&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>node3、node4分别执行:</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">source &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h6 id="1-5-2-5-启动ha的hadoop"><a href="#1-5-2-5-启动ha的hadoop" class="headerlink" title="1.5.2.5    启动ha的hadoop"></a>1.5.2.5    启动ha的hadoop</h6><p>a)    启动zookeeper集群, node2、node3、node4分别执行:</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">zkServer.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>b)    在node1\node2\node3上启动三台journalnode</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop-daemon.sh start journalnode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c)    选择node1，格式化HDFS</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>/var/bjsxt/hadoop/ha/dfs/name/current/目录下产生了fsimage文件<br>格式化后，启动namenode进程</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>d)    在另一台node2上同步元数据</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs namenode -bootstrapStandby<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>出现以下提示：</p><pre class="line-numbers language-none"><code class="language-none">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;About to bootstrap Standby ID nn2 from:           Nameservice ID: mycluster        Other Namenode ID: nn1  Other NN&#39;s HTTP address: http:&#x2F;&#x2F;node1:50070  Other NN&#39;s IPC  address: node1&#x2F;192.168.20.201:8020             Namespace ID: 178118551            Block pool ID: BP-1909026874-192.168.20.201-1577760263511               Cluster ID: CID-8105daf4-bdbb-40e8-a9d0-8d3f3867535b           Layout version: -60       isUpgradeFinalized: true&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>e)    初始化zookeeper上的内容 一定是在namenode节点（node1或node2）上。<br>执行格式命令之前在node2-node4任一节点上：</p><pre class="line-numbers language-none"><code class="language-none">[root@node4 hadoop]# zkCli.sh[zk: localhost:2181(CONNECTED) 0] ls &#x2F;[zookeeper]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>只有默认的一个节点。<br>接下来在node1上执行：</p><pre class="line-numbers language-none"><code class="language-none">[root@node1 ~]# hdfs zkfc -formatZK<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后在node4上接着执行</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[zk: localhost:2181(CONNECTED) 1] ls &#x2F;[zookeeper, hadoop-ha][zk: localhost:2181(CONNECTED) 2] ls &#x2F;hadoop-ha[mycluster][zk: localhost:2181(CONNECTED) 3] ls &#x2F;hadoop-ha&#x2F;mycluster[]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>f)    启动hadoop集群，可在node1到node4这四台服务器上任意位置执行</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 ~]# start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>node4上</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">node4上：[zk: localhost:2181(CONNECTED) 5] ls &#x2F;hadoop-ha&#x2F;mycluster[ActiveBreadCrumb, ActiveStandbyElectorLock] [zk: localhost:2181(CONNECTED) 6] get &#x2F;hadoop-ha&#x2F;mycluster&#x2F;ActiveStandbyElectorLockmyclusternn2node2 �&gt;(�&gt;cZxid &#x3D; 0x500000007ctime &#x3D; Tue Dec 31 11:04:24 CST 2019mZxid &#x3D; 0x500000007mtime &#x3D; Tue Dec 31 11:04:24 CST 2019pZxid &#x3D; 0x500000007cversion &#x3D; 0dataVersion &#x3D; 0aclVersion &#x3D; 0ephemeralOwner &#x3D; 0x26f599f159b0000dataLength &#x3D; 27numChildren &#x3D; 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>node2占用着锁，它的状态是active的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">1970 Jps1158 QuorumPeerMain1335 JournalNode1546 DataNode1660 DFSZKFailoverController1871 NameNode[root@node2 hadoop]# kill -9 1871[root@node2 hadoop]# jps1158 QuorumPeerMain1335 JournalNode1546 DataNode1980 Jps1660 DFSZKFailoverController<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    </p><p>node4上继续：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">node4上继续：[zk: localhost:2181(CONNECTED) 10] get &#x2F;hadoop-ha&#x2F;mycluster&#x2F;ActiveStandbyElectorLockmyclusternn2node1 �&gt;(�&gt;cZxid &#x3D; 0x50000000b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>node2访问不了，node1变为active<br>node2上再次启动namenode</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node2 hadoop]# hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>node2依然为standby。变为备机。</p><p>node1上停掉zkfc执行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 hadoop]# hadoop-daemon.sh stop zkfc#或[root@node1 hadoop]# jps1158 QuorumPeerMain1335 JournalNode1546 DataNode2012 NameNode1660 DFSZKFailoverController2111 Jps[root@node1 hadoop]# kill -9 1660[root@node1 hadoop]# jps1158 QuorumPeerMain1335 JournalNode2136 Jps1546 DataNode2012 NameNode<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>node2变为active状态<br>stop-dfs.sh停止hadoop服务。</p><p>node1上编写zk、hdfs启动脚本</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 ~]# vim starthdfs.sh#!&#x2F;bin&#x2F;bashfor node in node2 node3 node4do    ssh $node &quot;source &#x2F;etc&#x2F;profile;zkServer.sh start&quot;donesleep 1start-dfs.sh:wq[root@node1 ~]# chmod +x starthdfs.sh[root@node1 ~]# cp starthdfs.sh stopdfs.sh[root@node1 ~]# vim stopdfs.sh#!&#x2F;bin&#x2F;bashStop-dfs.shsleep 1for node in node2 node3 node4do    ssh $node &quot;source &#x2F;etc&#x2F;profile;zkServer.sh stop&quot;done:wq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果格式化之后，启动：<br>    启动三台zk<br>    随意节点：start-dfs.sh<br>    hadoop-daemon.sh stop namenode<br>    hadoop-daemon.sh stop zkfc</p><h6 id="1-5-2-6-zookeeper操作"><a href="#1-5-2-6-zookeeper操作" class="headerlink" title="1.5.2.6    zookeeper操作"></a>1.5.2.6    zookeeper操作</h6><p>在node2或者node3或者node4上运行</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">zkCli.shls &#x2F;hadoop-ha&#x2F;mycluster 查看临时文件 get &#x2F;hadoop-ha&#x2F;mycluster&#x2F;ActiveStandbyElectorLock 查看临时文件的内容#退出zkCli.shquit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以“hdfs haadmin -help <command>”查看帮助</p><p>transitionToActive和transitionToStandby - 将NameNode切换到Active或Standby状态<br>这两个命令不进行围栏操作，最好少用。最好使用“hdfs haadmin -failover”。</p><p>failover – 在指定的两个NameNode之间触发一个故障切换<br>如果第一个NameNode处于Standby状态，这个命令简单地让第二个NameNode处于Active状态，不报错。如果第一个处于Active状态，则尝试将它置于Standby状态。如果失败了，则fencing method会执行dfs.ha.fencing.methods列表中的下一个命令，直到有一个执行成功。在这之后才会将第二个NameNode转换为Active状态。如果没有fencing method成功，第二个NameNode不会转换为Active状态，同时报错。</p><p>getServiceState – 返回指定的NameNode处于Active或Standby状态<br>连接给定的NameNode并获取它的状态，返回“standby”或“active”到标准输出。这个命令用于定时器作业或监控脚本等需要根据NameNode状态执行不同操作的场合。</p><p>getAllServiceState – 返回所有NameNode的状态<br>连接到所有配置的NameNode，在标准输出为每个NameNode打印“standby”或“active”。</p><p>checkHealth – 检查给定NameNode的健康状态<br>连接到指定的NameNode并检查其健康状态。NameNode会进行自我诊断，包括检查内部服务是否正常运行。如果NameNode运行正常，则返回0，非0表示运行不正常。一般监控的时候使用。<br>需要注意的是，该命令还没有实现，当前如果不是NameNode宕机，只返回成功。</p><h4 id="1-6-java客户端操作HDFS-gt-gt-（python可调用java-api）"><a href="#1-6-java客户端操作HDFS-gt-gt-（python可调用java-api）" class="headerlink" title="1.6    java客户端操作HDFS &gt;&gt; （python可调用java api）"></a>1.6    java客户端操作HDFS &gt;&gt; （python可调用java api）</h4><h5 id="1-6-1-windows上部署hadoop包"><a href="#1-6-1-windows上部署hadoop包" class="headerlink" title="1.6.1    windows上部署hadoop包"></a>1.6.1    windows上部署hadoop包</h5><h5 id="1-6-2-windows环境变量配置"><a href="#1-6-2-windows环境变量配置" class="headerlink" title="1.6.2    windows环境变量配置"></a>1.6.2    windows环境变量配置</h5><h5 id="1-6-3-eclipse插件-了解"><a href="#1-6-3-eclipse插件-了解" class="headerlink" title="1.6.3    eclipse插件(了解)"></a>1.6.3    eclipse插件(了解)</h5><h5 id="1-6-4-IDEA配置hadoop插件"><a href="#1-6-4-IDEA配置hadoop插件" class="headerlink" title="1.6.4    IDEA配置hadoop插件"></a>1.6.4    IDEA配置hadoop插件</h5><h5 id="1-6-5-HDFS-API"><a href="#1-6-5-HDFS-API" class="headerlink" title="1.6.5    HDFS API"></a>1.6.5    HDFS API</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> hdfsimprot <span class="token operator">*</span><span class="token comment">#创建连接</span>client <span class="token operator">=</span> Client<span class="token punctuation">(</span><span class="token string">"http://192.168.40.101:50070/"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>client<span class="token punctuation">.</span>status<span class="token punctuation">(</span><span class="token string">"/data"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#创建目录</span>client<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'/data/api'</span><span class="token punctuation">)</span><span class="token comment">#删除</span>client<span class="token punctuation">.</span>delete<span class="token punctuation">(</span><span class="token string">'/data/api'</span><span class="token punctuation">,</span>recursive<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''recursive:flase 被删除的为目录是，只能删除空目录'''</span><span class="token comment">#上传</span>client<span class="token punctuation">.</span>upload<span class="token punctuation">(</span>hdfs_path<span class="token punctuation">,</span> local_path<span class="token punctuation">,</span> n_threads<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> temp_dir<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>chunk_size<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">**</span> <span class="token number">16</span><span class="token punctuation">,</span> progress<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> cleanup<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token comment">#下载# 有问题  会报错</span>client<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">"/data/api/hh.txt"</span><span class="token punctuation">,</span><span class="token string">'./.hhh.txt'</span><span class="token punctuation">,</span>overwrite<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-MapReduce"><a href="#3-MapReduce" class="headerlink" title="3 MapReduce"></a>3 MapReduce</h3><h4 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h4><p>mapreduce原语（独创）<br>mapreduce工作流程（重点）<br>MR作业提交流程（重点）<br>YARN RM-HA搭建（熟练）<br>运行自带的wordcount（了解）<br>动手写wordcount（熟练）</p><h4 id="1-2-MapReduce概述"><a href="#1-2-MapReduce概述" class="headerlink" title="1.2    MapReduce概述"></a>1.2    MapReduce概述</h4><p>map     映射<br>Reduce  汇聚、缩减</p><p>目标：普通人都能理解的理论基础<br>比如：如何统计北京一共有多少栋楼房？<br>源数据：<br>Haidian 200   Haidian 230  Haidian 200  Haidian 230<br>Haidian 300   Haidian 330<br>Haidian 400   Haidian 420<br>Haidian 500   Haidian 540<br>Haidian 600   Haidian 120 </p><p>Map-&gt;<br>Haidian  200<br>Haidian 230<br>Haidian  200<br>Haidian   200,300,400,230,600</p><p>Reducer:<br> Haidian  sum<br><a href="https://ibb.co/VNPqJbP">工作流程</a><br><strong>原语</strong>:&lt;&lt;相同的key为一组,这一组数据调用一次reduce方法,方法内迭代计算这一组数据&gt;&gt;<br>Map-Reduce: 线性依赖关系,先执行完map,再执行reduce</p><p>MapTask:<br>    映射:保证原语中组的实现<br>    并行度:split<br>        split:大小可调整,默认等于hdfs中block的大小<br>        框架默认,hdfs一个文件多少个block,就会有多少个map<br>    计算级别:split中一条记录(record)调用一次map方法!</p><p>ReduceTask:<br>    汇聚:<br>    计算级别:按照组group为单位,一组调用一次reduce方法!<br>    并行度:<br>        理想状态:多少组group对应多少个reduceTask<br>但是,其实一个reduceTask可以线性处理若干组<br>术语对比关系:<br>术语对比关系:<br>•    block &gt; split<br>    –    1:1（默认）<br>    –    N:1 (运算量较少的时候)<br>    –    1:N (运算量较大的时候)<br>•    split &gt; map<br>    –    1:1<br>•    map &gt; reduce<br>    –    N:1<br>    –    M:N<br>    –    1:1<br>    –    1:N<br>•    group(key)&gt;partition（redues task）     reduce(){}<br>    –    1:1<br>    –    N:1<br>    –    M:N<br>    –    1:N?  &gt;违背了原语<br>•    partition &gt; outputfile</p><p>1、每个block会有map任务<br>2、block切分为切片，每个切片对应一个map任务，默认一个block一个切片，一个map<br>3、map默认按行读取切片数据，组成键值对&lt;当前行字节偏移量, “读到的行字符串”&gt;<br>4、map函数对该键值对进行计算，输出若干键值对。&lt;key, value, partition&gt;<br>    partition指定该键值对由哪个reducer进行处理<br>5、map输出的kvp写到环形缓冲区，环形缓冲区默认100MB，阈值80%，当环缓达到80%就向磁盘溢写小文件，该小文件首先按照分区号排序，相同分区号的按key进行排序。<br>6、默认如果落磁盘的小文件达到了3个，则进行归并，归并的大文件也是按分区号排序，相同分区号按照key进行排序。只是一个归并。<br>7、如果map任务处理完了，它的输出被下载到reducer所在主机<br>    按照HTTP GET的方式下载到reducer：<br>    reducer发送HTTP GET请求到mapper主机下载数据，该过程是洗牌shuffle<br>8、每个map任务都要经历运行结束洗牌的过程<br>9、可以设置combinClass，先在map端对数据进行一个压缩，比如10w个&lt;hello,1&gt;压缩为1个&lt;hello, 10w&gt;通过网络IO洗牌，肯定要快很多。一般情况下，combineClass就是一个reducerClass</p><h4 id="1-3-mapreduce工作流程"><a href="#1-3-mapreduce工作流程" class="headerlink" title="1.3    mapreduce工作流程"></a>1.3    mapreduce工作流程</h4><p>官方给的定义：系统执行排序、将map输出作为输入传给reducer的过程称为Shuffle。（看完是不是一脸懵逼）通俗来讲，就是从map产生输出开始到reduce消化输入的整个过程称为Shuffle。如下图用黑线框出的部分：<br><a href="https://ibb.co/bNHHgSs">展示</a><br><strong>圆形缓冲区介绍</strong><br><a href="https://ibb.co/K61mT99">缓冲</a><br>每一个map任务都会有一个圆形缓冲区。默认大小100MB（io.sort.mb属性）阈值0.8也就是80MB**(mapreduce.map.sort.spill.percent属性指定）**</p><p><a href="https://ibb.co/wzwjZfG">缓冲</a></p><p>一旦达到阈值一个后台线程开始把内容写到(spill)磁盘的指定目录**[mapred.local.dir]**下的新建的一个溢出写文件。写入磁盘前先partition、sort、[combiner]。一个map task任务可能产生N个磁盘文件。map task运算完之后，产生了N个文件，然后将这些文件merge合成一个文件。<br>如果N=2，合成的新文件写入磁盘前只经过patition（分区）和sort（排序）过程，不会执行combiner合并（无论是否指定combiner类），如下图所示：<br><a href="https://ibb.co/JnHz49q">图示</a></p><p>如果N&gt;=3，合成的新文件写入磁盘前经过patition（分区）、sort（排序）过和combiner合并（前提是指定了combiner类），如下图所示：<br><a href="https://ibb.co/G5g8D4K">图示</a></p><p><strong>Q:思考：为什么只有当N&gt;=3时，合成文件才会执行combiner呢？</strong><br>A:这是因为如果N&lt;3时，执行combiner虽然减少了文件的大小，但是同时产生了一定的系统开销。由于减少的文件大小不大，权衡利弊后，确定N&lt;2时不在执行combiner操作。当该map task全部执行完之后，对应的reduce task将会拷贝对应分区的数据（该过程称为fetch），如下图所示：<br><a href="https://ibb.co/58Zt9MK">图示</a><br>其它的map task任务完成后，对应的reduce task也同样执行fetch操作，如下图所示：<br><a href="https://ibb.co/b7GZC9Q">图示</a></p><p>每个map任务的完成时间可能不同，因此只要有一个任务完成，reduce任务就开始复制其输出。该阶段被称为reduce的复制阶段。reduce任务有少量复制线程，因此能够并行取得map输出。默认值是5个线程，但这个默认值可以通过设置**[mapred.reduce.parallel.copies]**属性改变。<br><a href="https://ibb.co/gv1V8n3">图示</a></p><p>复制完所有map输出后，reduce任务进入合并阶段，该阶段将合并map输出，并维持其顺序排序（相当于执行了sort），如果指定了combiner，在写入磁盘前还会执行combiner操作。</p><p><strong>那么具体是如何合并的呢？</strong><br>合并因子默认是10，可以通过io.sort.factor属性设置。合并过程是循环进行了，可能叫经过多趟合并。目标是合并最小数量的文件以便满足最后一趟的合并系数。假设有40个文件，我们不会在四趟中每趟合并10个文件从而得到4个文件。相反，第一趟只合并4个文件，随后的三趟分别合并10个文件。再最后一趟中4个已合并的文件和余下的6个（未合并的）文件合计10个文件。具体流程如下图所示：<br><a href="https://ibb.co/cDSgf5d">图示</a></p><p>注意：这并没有改变合并次数，它只是一个优化措施，目的是尽量减少写到磁盘的数据量，因为最后一趟总是直接合并到reduce。<br>看到这里您是否理解了Shuffle的具体原理呢，如果没有，也没有关系，接下来我们通过一个wordcount案例再将整个流程梳理一遍。首先map任务的代码如下:</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">cn<span class="token punctuation">.</span>geekmooc</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Mapper</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span> ikey<span class="token punctuation">,</span> <span class="token class-name">Text</span> ivalue<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">&#123;</span><span class="token class-name">String</span> line <span class="token operator">=</span> ivalue<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">String</span> words<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://ibb.co/8NRk5Nm">分区</a><br>在分区（分区规则：按首字母分四个区，分别为a-i,j-q,r-z,其它）的过程中，会将相同的单词合并到一起，将出现次数用逗号隔开，如上图所示。注意此时还没有排序。分区代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">cn<span class="token punctuation">.</span>geekmooc</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Partitioner</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCPatitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">LongWritable</span> value<span class="token punctuation">,</span> <span class="token keyword">int</span> numPartitions<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token keyword">int</span> first_char <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">charAt</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>first_char<span class="token operator">>=</span><span class="token number">97</span><span class="token operator">&amp;&amp;</span>first_char<span class="token operator">&lt;=</span><span class="token number">105</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token comment">//a- j</span><span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>first_char<span class="token operator">>=</span><span class="token number">106</span><span class="token operator">&amp;&amp;</span>first_char<span class="token operator">&lt;=</span><span class="token number">113</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token comment">//k-q</span><span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>first_char<span class="token operator">>=</span><span class="token number">114</span><span class="token operator">&amp;&amp;</span>first_char<span class="token operator">&lt;=</span><span class="token number">122</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token comment">//r-  z</span><span class="token keyword">return</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span><span class="token keyword">return</span> <span class="token number">3</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接着执行排序操作，默认排序规则是按照key的字典升序排序，当然你也可以指定排序规则，排序后如下图所示<br><a href="https://ibb.co/j4STHVq">图示</a></p><p>接下来执行combiner操作，将每个单词后续的1求和，WCCombiner类代码如下:</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">cn<span class="token punctuation">.</span>tedu</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Iterator</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span><span class="token punctuation">&#123;</span><span class="token annotation punctuation">@Override</span><span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> values<span class="token punctuation">,</span><span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span><span class="token punctuation">.</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">&#123;</span> <span class="token class-name">Iterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> iter <span class="token operator">=</span> values<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">long</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token keyword">while</span><span class="token punctuation">(</span>iter<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span> count <span class="token operator">+=</span> iter<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://ibb.co/C2cfY0h">结果</a><br>combiner的结果如上图所示<br>map任务执行完，产生N个spill文件，接着对N个文件进行合并，分以下两种情况：1.N&lt;3，无论是否指定combiner类，合并文件时都不会执行combiner<br><a href="https://ibb.co/Rhjxg0G">图示</a></p><p>2.N&gt;=3,如果指定了combiner类将执行combiner操作，如下图：<br><a href="https://ibb.co/6mL5Ddz">combiner操作</a></p><p>接下来进入fetch（或copy）阶段<br><a href="https://ibb.co/RhLmbLP">fetch阶段</a></p><p>然后在reduce端进行合并<br>然后执行最后一趟合并，并将结果直接传给reduce<br><a href="https://ibb.co/3hYJVxH">结果</a><br>reduce类代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">cn<span class="token punctuation">.</span>geekmooc</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span><span class="token annotation punctuation">@Override</span><span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> values<span class="token punctuation">,</span><span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span><span class="token punctuation">.</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">&#123;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span>values<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">long</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">LongWritable</span> val <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>count <span class="token operator">+=</span> val<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span>context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>reduce task执行后，输出结果：<br><a href="https://ibb.co/HCd6QX4">结果</a></p><h4 id="1-1-Hadoop-1-x（了解）"><a href="#1-1-Hadoop-1-x（了解）" class="headerlink" title="1.1 Hadoop 1.x（了解）"></a>1.1 Hadoop 1.x（了解）</h4><h5 id="1-4-1-架构"><a href="#1-4-1-架构" class="headerlink" title="1.4.1    架构"></a>1.4.1    架构</h5><p><a href="https://ibb.co/pXjX9rD">架构</a></p><p>体现计算向数据移动<br><a href="https://ibb.co/qyD9LzS">data_map</a><br><a href="https://ibb.co/TPwsz4W">data_reduce</a></p><p>•    MRv1角色：<br>    –    JobTracker<br>        •    核心，主，单点<br>        •    调度所有的作业<br>        •    监控整个集群的资源负载<br>    –    TaskTracker<br>        •    从自身节点资源管理<br>        •    和JobTracker心跳，汇报资源，获取Task<br>    –    Client<br>        •    作业为单位<br>        •    规划作业计算分布<br>        •    提交作业资源到HDFS<br>        •    最终提交作业到JobTracker</p><p>•    弊端：<br>    –    JobTracker：负载过重，单点故障<br>    –    资源管理与计算调度强耦合，其他计算框架需要重复实现资源管理<br>    –    不同框架对资源不能全局管理</p><h5 id="1-4-2-MR执行流程（扩展阅读）"><a href="#1-4-2-MR执行流程（扩展阅读）" class="headerlink" title="1.4.2    MR执行流程（扩展阅读）"></a>1.4.2    MR执行流程（扩展阅读）</h5><p>一、4个独立的实体：<br>    1.    客户端：提交MapReduce作业<br>    2.    jobtracker：协调作业的运行，它是一个Java应用程序，它的主类时JobTracker<br>    3.    tasktracker:运行作业划分后的任务，它是Java应用程序，它的主类时TaskTracker。<br>    4.    HDFS：分布式文件系统，用来在其他实体间共享作业文件。</p><p>二、具体执行流程：<br><a href="https://ibb.co/NSbrhk0">执行流程</a></p><ol><li>客户端提交一个mr的jar包给JobClient(提交方式：hadoop jar …)</li><li>   JobClient通过RPC和JobTracker）进行通信，返回一个存放jar包的地址（HDFS）和jobId</li><li><pre><code>   client将运行作业所需要的资源（包括JAR文件、配置文件和计算所得的输入分片）复制到HDFS中的以作业id命名的目录下(path = hdfs上的地址 + jobId) </code></pre></li><li><pre><code>   开始提交任务(任务的描述信息，不是jar, 包括jobid，jar存放的位置，配置信息等等) </code></pre></li><li><pre><code>   JobTracker进行初始化任务</code></pre></li><li>   读取HDFS上的要处理的文件，开始计算输入分片，每一个分片对应一个MapperTask</li><li>   TaskTracker通过心跳机制领取任务（任务的描述信息）</li><li>   下载所需的jar，配置文件等</li><li>   TaskTracker启动一个java child子进程，</li><li>   用来执行具体的任务（MapperTask或ReducerTask）将结果写入到HDFS当中</li></ol><h4 id="1-5-Hadoop2-x"><a href="#1-5-Hadoop2-x" class="headerlink" title="1.5    Hadoop2.x"></a>1.5    Hadoop2.x</h4><h5 id="1-5-1-架构"><a href="#1-5-1-架构" class="headerlink" title="1.5.1    架构"></a>1.5.1    架构</h5><p><a href="https://ibb.co/NycGnwn">架构</a><br>•    MRv2：On YARN<br>    –    YARN：解耦资源与计算<br>        •    ResourceManager<br>            –    主，核心<br>            –    集群节点资源管理<br>        •    NodeManager<br>            –    与RM汇报资源<br>            –    管理Container生命周期<br>            –    计算框架中的角色都以Container表示<br>        •    Container：【节点NM，CPU,MEM,I/O大小，启动命令】<br>            –    默认NodeManager启动线程监控Container大小，超出申请资源额度，kill<br>            –    支持Linux内核的Cgroup<br>    –    MR ：<br>        •    MR-ApplicationMaster-Container<br>            –    作业为单位，避免单点故障，负载到不同的节点<br>            –    创建Task需要和RM申请资源（Container）<br>        •    Task-Container<br>    –    Client：<br>        •    RM-Client：请求资源创建AM<br>        •    AM-Client：与AM交互</p><p>YARN<br>    –    YARN：Yet Another Resource Negotiator；<br>    –    Hadoop 2.0新引入的资源管理系统，直接从MRv1演化而来的；<br>        –    核心思想：将MRv1中JobTracker的资源管理和任务调度两个功能分开，分别由ResourceManager和ApplicationMaster进程实现<br>        –    ResourceManager：负责整个集群的资源管理和调度<br>        –    ApplicationMaster：负责应用程序相关的事务，比如任务调度、任务监控和容错等<br>    –    YARN的引入，使得多个计算可运行在一个集群中<br>        –    每个job对应一个ApplicationMaster<br>        –    目前多个计算框架可以运行在YARN上，比如MapReduce、Spark、Storm等</p><p>MapReduce  On  YARN：MRv2<br>–    将MapReduce作业直接运行在YARN上，而不是由JobTracker和TaskTracker构建的MRv1系统中<br>–    基本功能模块<br>    –    YARN：负责资源管理和调度<br>    –    MRAppMaster：负责任务切分、任务调度、任务监控和容错等<br>    –    MapTask/ReduceTask：任务驱动引擎，与MRv1一致</p><p>–    每个MapRduce作业对应一个MRAppMaster<br>    –    MRAppMaster任务调度<br>    –    YARN将资源分配给MRAppMaster<br>    –    MRAppMaster进一步将资源分配给内部的任务</p><p>–    MRAppMaster容错<br>    –    失败后，由YARN重新启动<br>    –    任务失败后，MRAppMaster重新申请资源<br>    <a href="https://ibb.co/mcQ0MWK">容错</a></p><h5 id="1-5-2-MR执行流程"><a href="#1-5-2-MR执行流程" class="headerlink" title="1.5.2    MR执行流程"></a>1.5.2    MR执行流程</h5><p><a href="https://ibb.co/xLZpjsx">执行流程</a><br>一．    作业提交：</p><ol><li>   提交作业job后，job.waitForCompletion（true）调用monitorAndPrintJob()方法每秒轮询作业进度，如果发现自上次报告后有改变，便把进度报告给控制台。Job的submit()方法创建一个内部的JobSubmitter实例，并调用其submitJobInternal方法（步骤1）。作业完成后，如果成功，就显示计数器；如果失败，这将导致作业失败的错误记录到控制台。</li></ol><p>JobSubmitter所实现的作业提交过程如下所述：<br>2.    向资ResourceManager源管理器请求一个新作业的ID，用于MapReduce作业ID。<br>3.    作业客户端检查作业的输出说明，计算输入分片splits并将作业资源（包括作业Jar包、配置文件和分片信息）复制到HDFS<br>4.    通过调用资源管理器上的submitApplication（）方法提交作业</p><p>二．    作业初始化<br>5.    资源管理器ResourceManager收到调用他的submitApplication（）消息后，便将请求传递给调度器（scheduler）。调度器分配一个容器（Container），然后资源管理器在节点管理器（NodeManager）的管理下载容器中启动应用程序的master进程（步骤5a和5b）<br>6.    MapReduce作业的application master是一个Java应用程序，它的主类是MRAppMaster。它对作业进行初始化：通过创建多个簿记对象以保持对作业进度的跟踪，因为它将接受来自任务的进度和完成报告（步骤6）。</p><ol start="7"><li>   接下来，它接受来自共享文件系统的在客户端计算的输入分片（步骤7）。对每一个分片创建一个map任务对象以及由mapreduce. job.reduces属性确定的多个reduce任务对象。</li></ol><p>三．    任务分配<br>8.    AppMaster为该作业中的所有map任务和reduce任务向资源管理器请求容器。</p><p>四．    任务执行<br>9.    一旦资源管理器的调度器为任务分配了容器，AppMaster就通过与节点管理器NodeManager通讯来启动容器（步骤9a和9b）。<br>10.    该任务由主类为YarnChild的Java应用程序执行。在它允许任务之前，首先将任务需要的资源本地化，包括作业的配置、JAR文件和所有来自分布式缓存的文件.<br>11.    最后运行map任务或reduce任务。</p><p>五．    进度和状态更新<br>在YARN下运行时，任务每3秒钟通过umbilical接口向APPMaster汇报进度和状态。客户端每一秒钟（通过mapreduce.client.<br>Progressmonitor.pollinterval设置）查询一次AppMaster以接收进度更新，通常都会向用户显示。</p><p>六．    作业完成<br>除了向AppMaster查询进度外，客户端每5秒还通过调用Job的waitForCompletion()来检测作业是否完成。查询的间隔可以通过mapreduce.client.completion.pollinterval属性进行设置。作业完成后，AppMaster和任务容器清理器工作状态。</p><h4 id="1-6-YARN-RM-HA搭建"><a href="#1-6-YARN-RM-HA搭建" class="headerlink" title="1.6    YARN RM-HA搭建"></a>1.6    YARN RM-HA搭建</h4><p><a href="https://hadoop.apache.org/docs/r2.6.5/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">高可用</a></p><p><a href="https://ibb.co/FYzy7T2">rm-ha</a></p><h5 id="1-6-1-mapred-site-xml"><a href="#1-6-1-mapred-site-xml" class="headerlink" title="1.6.1    mapred-site.xml"></a>1.6.1    mapred-site.xml</h5><p>local/classic/yarn<br>指定mr作业运行的框架：要么本地运行，要么使用MRv1，要么使用yarn</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="1-6-2-yarn-site-xml"><a href="#1-6-2-yarn-site-xml" class="headerlink" title="1.6.2    yarn-site.xml"></a>1.6.2    yarn-site.xml</h5><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 让yarn的容器支持mapreduce的洗牌，开启shuffle服务 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- 启用resourcemanager的HA --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.ha.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- 指定zookeeper集群的各个节点地址和端口号 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.zk-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node2:2181,node3:2181,node4:2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- 标识集群，以确保 RM 不会接管另一个集群的活动。 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.cluster-id<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>cluster1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- RM HA的两个resourcemanager的名字 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.ha.rm-ids<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>rm1,rm2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- 指定rm1的reourcemanager进程所在的主机名称 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.hostname.rm1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment">&lt;!-- 指定rm2的reourcemanager进程所在的主机名称 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.hostname.rm2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将配置文件在四台服务器同步</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 hadoop]# pwd&#x2F;opt&#x2F;hadoop-2.6.5&#x2F;etc&#x2F;hadoop[root@node1 hadoop]scp mapred-site.xml yarn-site.xml  node[234]:&#96;pwd&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>node1:</strong><br>首先启动HDFS<br>start-ha.sh</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;bin&#x2F;bashfor node in node2 node3 node4do   ssh $node &quot;source &#x2F;etc&#x2F;profile; zkServer.sh start&quot;donesleep 1start-dfs.shecho &quot;--------------node1-jps----------------&quot;jpsfor node in node2 node3 node4do  echo &quot;---------------$node-jps-------------------&quot;  ssh $node &quot;source &#x2F;etc&#x2F;profile; jps&quot;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在node3和node4上执行命令,启动ResourceManager：<br>Node3:<br>start-yarn.sh（只能启动本机上的ResourceManager和其他节点的NodeManager）<br>Node4:<br>yarn-daemon.sh  start  resourcemanager</p><p><a href="http://node3:8088/">http://node3:8088</a><br><a href="https://ibb.co/BsL5kpG">结果</a></p><p><a href="http://node4:8088/cluster/cluster">http://node4:8088/cluster/cluster</a><br><a href="https://ibb.co/WBsr3cP">结果</a></p><p><strong>高可用演示：</strong><br>node3上执行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yarn-deamon.sh  stop  resourcemanager<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="http://node4:8088/cluster/cluster%E5%8F%98%E4%B8%BAactive%E7%9A%84%E3%80%82">http://node4:8088/cluster/cluster变为active的。</a><br><a href="https://ibb.co/sF8HB2Z">图示</a></p><h4 id="1-7-运行自带的wordcount"><a href="#1-7-运行自带的wordcount" class="headerlink" title="1.7    运行自带的wordcount"></a>1.7    运行自带的wordcount</h4><h5 id="1-7-1-运行的命令："><a href="#1-7-1-运行的命令：" class="headerlink" title="1.7.1    运行的命令："></a>1.7.1    运行的命令：</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">root@node1 ~]# vim wc.txthello  tomandy  joyhello  rosehello  joymark  andyhello  tomandy  rosehello  joy[root@node1 ~]# hdfs dfs -mkdir &#x2F;input[root@node1 ~]# hdfs dfs -put wc.txt &#x2F;input[root@node1 ~]# hdfs dfs -ls &#x2F;input-rw-r--r--   2 root supergroup         88 2020-02-23 22:28 &#x2F;input&#x2F;wc.txt[root@node1 ~]# cd &#x2F;opt&#x2F;hadoop-2.6.5&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;[root@node1 mapreduce]#hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount  &#x2F;input  &#x2F;output[root@node1 mapreduce]# hdfs dfs -ls &#x2F;output-rw-r--r--   2 root supergroup          0 2020-02-23 22:31 &#x2F;output&#x2F;_SUCCESS-rw-r--r--   2 root supergroup         41 2020-02-23 22:31 &#x2F;output&#x2F;part-r-00000[root@node1 mapreduce]# cd[root@node1 ~]#hdfs dfs -get &#x2F;output&#x2F;part-r-00000[root@node1 ~]#ls[root@node1 ~]#cat part-r-00000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>*input:是hdfs文件系统中数据所在的目录<br>*ouput:是hdfs中不存在的目录，mr程序运行的结果会输出到该目录</p><h5 id="1-7-2-输出目录内容："><a href="#1-7-2-输出目录内容：" class="headerlink" title="1.7.2    输出目录内容："></a>1.7.2    输出目录内容：</h5><p>-rw-r–r–   3 root supergroup          0 2017-07-02 02:49 /mr/test/output/_SUCCESS<br>-rw-r–r–   3 root supergroup         49 2017-07-02 02:49 /mr/test/output/part-r-00000<br>/_SUCCESS：是信号/标志文件<br>/part-r-00000：是reduce输出的数据文件<br>r：reduce的意思，00000是对应的reduce编号，多个reduce会有多个数据文件</p><h5 id="1-7-3-启动脚本和停止脚本："><a href="#1-7-3-启动脚本和停止脚本：" class="headerlink" title="1.7.3    启动脚本和停止脚本："></a>1.7.3    启动脚本和停止脚本：</h5><p>start-hdfs-ha-rm-ha.sh</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;bin&#x2F;bashfor node in node2 node3 node4do   ssh $node &quot;source &#x2F;etc&#x2F;profile; zkServer.sh start&quot;donesleep 1start-dfs.shssh node3 &quot;. &#x2F;etc&#x2F;profile; start-yarn.sh&quot;ssh node4 &quot;. &#x2F;etc&#x2F;profile; yarn-daemon.sh start resourcemanager&quot;echo &quot;--------------node1-jps----------------&quot;jpsfor node in node2 node3 node4do  echo &quot;---------------$node-jps-------------------&quot;  ssh $node &quot;source &#x2F;etc&#x2F;profile; jps&quot;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>stop-hdfs-ha-rm-ha.sh</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;bin&#x2F;bashssh node4 &quot;. &#x2F;etc&#x2F;profile; stop-yarn.sh&quot;ssh node3 &quot;. &#x2F;etc&#x2F;profile; yarn-daemon.sh stop resourcemanager&quot;stop-dfs.shfor node in node2 node3 node4do  ssh $node &quot;source &#x2F;etc&#x2F;profile; zkServer.sh stop&quot;doneecho &quot;-------------node1-jps-----------------&quot;jpsfor node in node2 node3 node4do  echo &quot;---------------$node-jps-----------------&quot;  ssh $node &quot;source &#x2F;etc&#x2F;profile; jps&quot;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-8-动手写wordcount"><a href="#1-8-动手写wordcount" class="headerlink" title="1.8    动手写wordcount"></a>1.8    动手写wordcount</h4><h5 id="1-8-1-新建java项目"><a href="#1-8-1-新建java项目" class="headerlink" title="1.8.1    新建java项目"></a>1.8.1    新建java项目</h5><h5 id="1-8-2-添加hadoop的jar包依赖"><a href="#1-8-2-添加hadoop的jar包依赖" class="headerlink" title="1.8.2    添加hadoop的jar包依赖"></a>1.8.2    添加hadoop的jar包依赖</h5><p>121个jar包<br>$HADOOP_HOME/share/hadoop/{common,common/lib,hdfs,hdfs/lib,mapreduce,mapreduce/lib,tools/lib,yarn,yarn/lib}.jar</p><h5 id="1-8-3-添加hadoop的配置文件到类路径"><a href="#1-8-3-添加hadoop的配置文件到类路径" class="headerlink" title="1.8.3    添加hadoop的配置文件到类路径"></a>1.8.3    添加hadoop的配置文件到类路径</h5><p>从集群拷贝这四个文件到当前项目类路径<br>core-site.xml<br>hdfs-site.xml<br>mapred-site.xml<br>yarn-site.xml</p><h5 id="1-8-4-编写Mapper、Reducer以及MainClass"><a href="#1-8-4-编写Mapper、Reducer以及MainClass" class="headerlink" title="1.8.4    编写Mapper、Reducer以及MainClass"></a>1.8.4    编写Mapper、Reducer以及MainClass</h5><h6 id="1-8-4-1-WCMapper-java"><a href="#1-8-4-1-WCMapper-java" class="headerlink" title="1.8.4.1    WCMapper.java"></a>1.8.4.1    WCMapper.java</h6><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>bjsxt<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Mapper</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span><span class="token keyword">private</span> <span class="token class-name">Text</span> outKey <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">private</span> <span class="token class-name">LongWritable</span> outValue <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token annotation punctuation">@Override</span><span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span> key<span class="token punctuation">,</span> <span class="token class-name">Text</span> value<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span><span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">&#123;</span><span class="token comment">//一句话  hello bjsxt 1</span><span class="token class-name">String</span> line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//将一句话按照空格隔开为单个单词</span><span class="token comment">// &#123;"hello", "bjsxt", "1"&#125;</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>outKey<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>outValue<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// &lt;"hello", 1></span><span class="token comment">// &lt;"bjsxt", 1></span><span class="token comment">// &lt;"1", 1></span>context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>outKey<span class="token punctuation">,</span> outValue<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="1-8-4-2-WCReducer-java"><a href="#1-8-4-2-WCReducer-java" class="headerlink" title="1.8.4.2    WCReducer.java"></a>1.8.4.2    WCReducer.java</h6><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>bjsxt<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Iterator</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WCReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span><span class="token keyword">private</span> <span class="token class-name">LongWritable</span> outValue <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token annotation punctuation">@Override</span><span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span><span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">&#123;</span><span class="token comment">// key表示的单词出现的次数，总数</span><span class="token keyword">long</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token comment">// 获取values的迭代器，用于遍历</span><span class="token class-name">Iterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">></span></span> itera <span class="token operator">=</span> values<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//&lt;"zhangsan", 1></span><span class="token comment">//&lt;"zhangsan-0", 1></span><span class="token comment">//&lt;"zhangsan-1", 1></span><span class="token comment">//&lt;"zhangsan-2", 1></span><span class="token comment">//&lt;"zhangsan-3", 1></span><span class="token comment">//&lt;"zhangsan-4", 1></span><span class="token keyword">while</span> <span class="token punctuation">(</span>itera<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token comment">// 获取该值</span><span class="token class-name">LongWritable</span> val <span class="token operator">=</span> itera<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 将该值转换为long类型</span><span class="token keyword">long</span> num <span class="token operator">=</span> val<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 逐个求和</span>sum <span class="token operator">+=</span> num<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">// 将总数封装为LongWritable类型对象</span>outValue<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 输出到HDFS</span>context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> outValue<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="1-8-4-3-MainClass-java"><a href="#1-8-4-3-MainClass-java" class="headerlink" title="1.8.4.3    MainClass.java"></a>1.8.4.3    MainClass.java</h6><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>bjsxt<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">Path</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Job</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">JobContext</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span></span><span class="token class-name">FileInputFormat</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span></span><span class="token class-name">FileOutputFormat</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MainClass</span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>args <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> args<span class="token punctuation">.</span>length <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Usage : yarn jar wc.jar com.bjsxt.mr.wordcount.MainClass &lt;input path> &lt;output path>"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Job</span> job <span class="token operator">=</span> <span class="token class-name">Job</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//设置主入口程序</span>job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span><span class="token class-name">MainClass</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 设置作业名称，该名称可以在UI上看到</span>job<span class="token punctuation">.</span><span class="token function">setJobName</span><span class="token punctuation">(</span><span class="token string">"我的数单词"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//Path inputPath = new Path("/mr/wc/input/hello.txt");</span><span class="token class-name">Path</span> inputPath <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//设置输入路径</span><span class="token class-name">FileInputFormat</span><span class="token punctuation">.</span><span class="token function">addInputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> inputPath<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//Path outputPath = new Path("/mr/wc/output");</span><span class="token class-name">Path</span> outputPath <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//指定输出路径，该路径一定不能存在</span><span class="token class-name">FileOutputFormat</span><span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> outputPath<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//指定mapper类</span>job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span><span class="token class-name">WCMapper</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//指定reducer类</span>job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span><span class="token class-name">WCReducer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//map输出键值对的key类型</span>job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span><span class="token class-name">Text</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//map端输出键值对的value类型</span>job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//提交作业</span>job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="1-8-5-本地运行测试"><a href="#1-8-5-本地运行测试" class="headerlink" title="1.8.5    本地运行测试"></a>1.8.5    本地运行测试</h5><p>如果想本地运行，则可以如此设置：<br>略》》》</p><h5 id="1-8-6-打包"><a href="#1-8-6-打包" class="headerlink" title="1.8.6    打包"></a>1.8.6    打包</h5><p>只打包三个类就可以。<br>略》》》</p><h5 id="1-8-7-上传"><a href="#1-8-7-上传" class="headerlink" title="1.8.7    上传"></a>1.8.7    上传</h5><h5 id="1-8-8-运行"><a href="#1-8-8-运行" class="headerlink" title="1.8.8    运行"></a>1.8.8    运行</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node1 ~]# yarn jar wc.jar com.bjsxt.mr.wordcount.MainClassUsage : yarn jar wc.jar com.bjsxt.mr.wordcount.MainClass &lt;input path&gt; &lt;output path&gt;[root@node1 ~]# yarn jar wc.jar com.bjsxt.mr.wordcount.MainClass &#x2F;input &#x2F;output2yarn   jar   [&#x2F;path&#x2F;to&#x2F;your&#x2F;]jar.jar package.MainClass  &#x2F;&lt;inputpath&gt;  &#x2F;&lt;outputpath&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-9-二次排序（先了解）"><a href="#1-9-二次排序（先了解）" class="headerlink" title="1.9    二次排序（先了解）"></a>1.9    二次排序（先了解）</h4><p>在map阶段按照key对键值对进行排序，对值不排序。如果相对value进行排序，就需要二次排序。</p><p>需求：查找每年的最高气温<br>数据格式：年份为key，每天的气温是value</p><p>所谓二次排序：<br>1、新的key应该是输入的key和value的组合<br>2、按照复合key进行比较排序<br>3、分区比较器和分组比较器只对复合key中的原生key进行分区和分组<br><a href="https://ibb.co/642yWvd">流程图</a></p><h3 id="4-mapreduce计算流程"><a href="#4-mapreduce计算流程" class="headerlink" title="4    mapreduce计算流程"></a>4    mapreduce计算流程</h3><h4 id="1-1-mapreduce计算流程"><a href="#1-1-mapreduce计算流程" class="headerlink" title="1.1    mapreduce计算流程"></a>1.1    mapreduce计算流程</h4><p>首先将block块进行逻辑切片的计算，每个切片（split）对应一个map任务<br>切片是为了将block数量和map任务数量解耦。<br>map读取切片数据，默认按行读取，作为键值对交给map方法，其中key是当前读取的行在文件中的字节偏移量，value就是读取的当前行的内容。<br>map开始计算，自定义的逻辑。<br>map将输出的kv首先写到环形缓冲区，在写之前计算分区号（默认按照key的hash值对reducer的个数取模）。<br>环形缓冲区默认100MB，阈值80%，如果写入的kv对达到了80%则发生溢写，溢写的时候要先对键值对按照分区号进行分区，相同分区按照key的字典序排序，溢写到磁盘。如果溢写的文件数量达到了三个，则发生map端归并操作，此时如果指定了combiner，则按照combiner合并数据。<br>当一个map任务完成之后，所有的reducertask向其发送http get请求，下载它们所属的分区数据。此过程称为shuffle，洗牌。<br>当所有map任务运行结束，开始reduce任务</p><p>在reduce开始之前，根据设定的归并因子，进行多伦的归并操作，非最后一轮的归并的结果文件被存入到硬盘上，最后一轮归并的结果直接传递给reduce，reduce迭代计算。<br>reduce计算结束后将结果写到HDFS文件中，每一个reducer task任务都会在作业输出路径下产生一个结果文件part-r-00xxx。同时执行成功时会产生一个空的_SUCCESS文件，该文件是一个标识文件。MR1-&gt;MR2-&gt;MR3</p><h4 id="1-2-作业提交流程"><a href="#1-2-作业提交流程" class="headerlink" title="1.2    作业提交流程"></a>1.2    作业提交流程</h4><p>1、    客户端向RM取号(获取作业的ID)<br>2、    客户端检查作业输入输出（如果输入路径不存在则抛出异常；如果输出路径存在也抛出异常），计算切片，解析配置信息<br>3、    客户端将jar包、配置信息以及切片信息上传到HDFS<br>4、    客户端向RM发送提交作业的请求<br>5、    RM调度一个NM，在NM上的一个容器中运行MRAppMaster，一个作业对应一个MRAppMaster。<br>6、    MRAppMaster首先获取HDFS中的作业信息，计算出当前作业需要多少个map任务，多少个reduce任务<br>7、    MRAppMaster（AM）向RM为map任务申请容器，AM跟NM通信把容器启动起来，运行map任务，容器中的YARNChild会首先本地化conf、切片信息以及jar包<br>8、    当map任务完成达到5%的时候，AM向RM为reduce任务申请容器<br>9、    当MR中最后一个任务运行结束，AM向客户端发送作业完成信息。MR的中间数据销毁，容器销毁，计算结果存档到历史服务器</p><h4 id="2-目标"><a href="#2-目标" class="headerlink" title="2    目标"></a>2    目标</h4><p>客户端作业提交源码分析<br>框架：MapTask<br>框架：ReduceTask</p><h4 id="2-1-客户端作业提交源码分析"><a href="#2-1-客户端作业提交源码分析" class="headerlink" title="2.1    客户端作业提交源码分析"></a>2.1    客户端作业提交源码分析</h4><p><a href="https://ibb.co/0n0ww1m">教程</a><br>Mapper类的map方法中添加：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">99999999</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">MainClass</span>类中注释掉：<span class="token comment">//configuration.set("mapreduce.framework.name","local");</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>重新打jar包，发布到服务器上运行：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yarn jar mywc.jar com.bjsxt.mr.wc.MainClass &lt;inputPath&gt; &lt;outputPath&gt;[root@node1 ~]# hdfs dfs -ls -R &#x2F;tmp&#x2F;hadoop-yarn&#x2F;[root@node1 ~]# hdfs dfs -get &#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;root&#x2F;.staging&#x2F;job_1582529707113_0005<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>查看job.xml（Ctrl+Alt+L格式化代码）<br>配置信息默认值一部分来自于MRJobConfig接口<br>一部分来自*-default.xml文件<br>一部分来自用户的设置：程序设置和xxx-site.xml设置<br>Configuration<br>xx-default.xml<br>xx-site.xml<br>MRJobConfig<br>观察默认值<br>JobContextImpl<br>JobConf conf<br>观察默认值<br>Job<br>set*()<br>waitForCompletion(true)</p><p>MainClass中使用<br>//提交作业，等待作业完成<br>job.waitForCompletion(true)</p><p>提交作业:<br>提交作业属于异步操作，当执行submit()方法之后，由于job.waitForCompletion(true)参数为true，所以会执行monitorAndPrintJob()方法不断打印输出执行的过程。</p><p>…. 略》》》 </p><h4 id="2-2-框架：MapTask"><a href="#2-2-框架：MapTask" class="headerlink" title="2.2    框架：MapTask"></a>2.2    框架：MapTask</h4><p>从切片读取数据，给map方法，map方法输出的键值对写到环形缓冲区<br>在写到环形缓冲区之前计算分区号<br>环形缓冲区排序后溢写到map端本地磁盘，可能会有合并的过程，3<br>可以设置环形缓冲区大小和阈值<br>排序所使用的算法：默认是快排，可以设置</p><p>可以自定义key和value<br>排序比较器可以自定义</p><p>可以设置Combiner</p><h5 id="2-2-1-map输入input"><a href="#2-2-1-map输入input" class="headerlink" title="2.2.1    map输入input"></a>2.2.1    map输入input</h5><h6 id="2-2-1-1-源码从哪里开始看？"><a href="#2-2-1-1-源码从哪里开始看？" class="headerlink" title="2.2.1.1    源码从哪里开始看？"></a>2.2.1.1    源码从哪里开始看？</h6><p><a href="https://ibb.co/xLZpjsx">流程</a></p><p>从YarnChild开始<br>在idea中通过alt+ctrl+&lt;-或-&gt;后退或前进<br>Ctrl+Shift+N -&gt;输入YarnChild-&gt;Ctrl+G (定位到哪一行)-&gt;输入163：1<br>YarnChild</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">final</span> <span class="token class-name">Task</span> taskFinal <span class="token operator">=</span> <span class="token class-name">Task</span><span class="token punctuation">;</span>childUGI<span class="token punctuation">.</span><span class="token function">doAs</span><span class="token punctuation">(</span><span class="token class-name">PrivilegedExceptAction</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>→<span class="token punctuation">&#123;</span><span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setWorkingDirectory</span><span class="token punctuation">(</span>job<span class="token punctuation">.</span><span class="token function">getWorkingDirectory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>taskFinal<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span>umbiilical<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//run the task</span><span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>光标点到run()方法名称上，Ctrl+Alt+B-&gt;选择MapTask类</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token class-name">JobConf</span> job<span class="token punctuation">,</span><span class="token class-name">TaskUmbilicalProtocal</span> umnilical<span class="token punctuation">)</span><span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span><span class="token class-name">ClassNotFoundException</span> <span class="token punctuation">,</span><span class="token class-name">InterrupteException</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>MapTask</p><p>MapTask实现了run方法：</p><h6 id=""><a href="#" class="headerlink" title=""></a></h6><p>2.2.1.2    runNewMapper真正执行Map任务(Hadoop2.x+)</p><hr><p>待续</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ZooKeeper</title>
      <link href="/2021/12/21/zookeeper/"/>
      <url>/2021/12/21/zookeeper/</url>
      
        <content type="html"><![CDATA[<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="1-ZooKeeper基础"><a href="#1-ZooKeeper基础" class="headerlink" title="1 ZooKeeper基础"></a>1 ZooKeeper基础</h3><h4 id="1-1为什么使用ZooKeeper"><a href="#1-1为什么使用ZooKeeper" class="headerlink" title="1.1为什么使用ZooKeeper"></a>1.1为什么使用ZooKeeper</h4><ol><li>   Nginx作为负载均衡管理大量服务器时，管理起来比较麻烦，可以通过zookeeper注册服务与发现服务协作管理。</li><li>   以前大部分应用需要开发私有的协调程序，缺乏一个通用的机制协调程序的反复编写浪费，且难以形成通用、伸缩性好的协调器</li><li>   使用分布式部署后，多线程安全的问题，以前学的同步代码块、重构锁、读写锁等通通失效，怎么办？</li></ol><h4 id="1-2-Zookeeper·概述"><a href="#1-2-Zookeeper·概述" class="headerlink" title="1.2 Zookeeper·概述"></a>1.2 Zookeeper·概述</h4><h5 id="1-2-1-ZooKeeper简介"><a href="#1-2-1-ZooKeeper简介" class="headerlink" title="1.2.1 ZooKeeper简介"></a>1.2.1 ZooKeeper简介</h5><p>ZooKeeper：动物园管理员<br>ZooKeeper是分布式应用程序的协调服务框架，是Hadoop的重要组件。ZooKeeper是Google的Chubby一个开源的实现，是Hadoop的分布式协调服务，包含一个简单的原语集，分布式应用程序可以基于它实现。</p><h5 id="1-2-2-具体应用场景"><a href="#1-2-2-具体应用场景" class="headerlink" title="1.2.2 具体应用场景"></a>1.2.2 具体应用场景</h5><ol><li>   Hadoop,使用ZooKeeper的事件处理确保整个集群只有一个NameNode,存储配置信息等.<br><a href="https://ibb.co/mJLWCJK">ZooKeeper_in_hadoop</a></li><li>   HBase,使用ZooKeeper的事件处理确保整个集群只有一个HMaster,察觉HRegionServer联机和宕机,存储访问控制列表等.</li></ol><h3 id="1-3-分布式编程容易出现的问题"><a href="#1-3-分布式编程容易出现的问题" class="headerlink" title="1.3 分布式编程容易出现的问题"></a>1.3 分布式编程容易出现的问题</h3><p>分布式的思想就是人多干活快，即用多台机器同时处理一个任务。分布式的编程和单机的编程 思想是不同的，随之也带来新的问题和挑战。<br>1.活锁。<br>活锁定义：在程序里，由于某些条件的发生碰撞，导致重新执行，再碰撞=》再执 行，如此循环往复，就形成了活锁。活锁的危害：多个线程争用一个资源，但是没有任何一个 线程能拿到这个资源。（死锁是有一个线程拿到资源，但相互等待互不释放造成死锁），活锁 是死锁的变种。补充：活锁更深层次的危害，很耗尽Cpu资源（在做无意义的调度）<br>2.需要考虑集群的管理问题，需要有一套机制来检测到集群里节点的状态变化。<br>3.如果用一台机器做集群管理，存在单点故障问题，所以针对集群管理，也需要形成一个集群<br>4.管理集群里Leader的选举问题（要根据一定的算法和规则来选举），包括要考虑Leader挂掉 之后，如何从剩余的follower里选出Leader<br>5.分布式锁的实现，用之前学的重入锁，同步代码块是做不了的</p><h3 id="1-4-Paxos的小岛的故事"><a href="#1-4-Paxos的小岛的故事" class="headerlink" title="1.4    Paxos的小岛的故事"></a>1.4    Paxos的小岛的故事</h3><p>那么ZooKeeper最基础的东西是什么呢？不得不提Paxos，它是一个基于消息传递的一致性算法，Leslie Lamport（莱斯利·兰伯特）在1990年提出，近几年被广泛应用于分布式计算中，Google的Chubby，Apache的ZooKeeper都是基于它的理论来实现的，Paxos还被认为是到目前为止唯一的分布式一致性算法，其它的算法都是Paxos的改进或简化。有个问题要提一下，Paxos有一个前提：没有拜占庭将军问题。就是说Paxos只有在一个可信的计算环境中才能成立，这个环境是不会被入侵所破坏的。<br>Paxos描述了这样一个场景，有一个叫做Paxos的小岛(Island)上面住了一批居民，岛上面所有的事情由一些特殊的人决定，他们叫做议员(Senator)。议员的总数(Senator Count)是确定的，不能更改。岛上每次环境事务的变更都需要通过一个提议(Proposal)，每个提议都有一个编号(PID)，这个编号是一直增长的，不能倒退。每个提议都需要超过半数((Senator Count)/2 +1)的议员同意才能生效。每个议员只会同意大于当前编号的提议，包括已生效的和未生效的。如果议员收到小于等于当前编号的提议，他会拒绝，并告知对方：你的提议已经有人提过了。这里的当前编号是每个议员在自己记事本上面记录的编号，他不断更新这个编号。整个议会不能保证所有议员记事本上的编号总是相同的。现在议会有一个目标：保证所有的议员对于提议都能达成一致的看法<br>好，现在议会开始运作，所有议员一开始记事本上面记录的编号都是0。有一个议员发了一个提议：将电费设定为1元/度。他首先看了一下记事本，嗯，当前提议编号是0，那么我的这个提议的编号就是1，于是他给所有议员发消息：1号提议，设定电费1元/度。其他议员收到消息以后查了一下记事本，哦，当前提议编号是0，这个提议可接受，于是他记录下这个提议并回复：我接受你的1号提议，同时他在记事本上记录：当前提议编号为1。发起提议的议员收到了超过半数的回复，立即给所有人发通知：1号提议生效！收到的议员会修改他的记事本，将1好提议由记录改成正式的法令，当有人问他电费为多少时，他会查看法令并告诉对方：1元/度<br>现在看冲突的解决：假设总共有三个议员S1-S3，S1和S2同时发起了一个提议:1号提议，设定电费。S1想设为1元/度, S2想设为2元/度。结果S3先收到了S1的提议，于是他做了和前面同样的操作。紧接着他又收到了S2的提议，结果他一查记事本，咦，这个提议的编号小于等于我的当前编号1，于是他拒绝了这个提议：对不起，这个提议先前提过了。于是S2的提议被拒绝，S1正式发布了提议: 1号提议生效。S2向S1或者S3打听并更新了1号法令的内容，然后他可以选择继续发起2号提议<br>好，我觉得Paxos的精华就这么多内容。现在让我们来对号入座，看看在ZK Server里面Paxos是如何得以贯彻实施的</p><p>小岛(Island)——ZK Server Cluster<br>议员(Senator)——ZK Server<br>提议(Proposal)——ZNode Change(Create/Delete/SetData…)<br>提议编号(PID)——Zxid(ZooKeeper Transaction Id)<br>正式法令——所有ZNode及其数据</p><p>貌似关键的概念都能一一对应上，但是等一下，Paxos岛上的议员应该是人人平等的吧，而ZK Server好像有一个Leader的概念。没错，其实Leader的概念也应该属于Paxos范畴的。如果议员人人平等，在某种情况下会由于提议的冲突而产生一个“活锁”（所谓活锁我的理解是大家都没有死，都在动，但是一直解决不了冲突问题）。Paxos的作者Lamport在他的文章”The Part-Time Parliament“中阐述了这个问题并给出了解决方案——在所有议员中设立一个总统，只有总统有权发出提议，如果议员有自己的提议，必须发给总统并由总统来提出。<br>好，我们又多了一个角色：总统。<br>总统——ZK Server Leader</p><h3 id="1-5-ZooKeeper集群"><a href="#1-5-ZooKeeper集群" class="headerlink" title="1.5    ZooKeeper集群"></a>1.5    ZooKeeper集群</h3><p>攘其外：消息队列<br>安其内：选举<br>现在我们假设总统已经选好了，下面看看ZK 是怎么实施的。<br>情况一：<br>总统突然挂了，议员接二连三的发现联系不上总统，于是各自发表声明，推选新的总统，总统大选期间政府停业，拒绝屁民的请求。呵呵，到此为止吧，当然还有很多其他的情况，但这些情况总是能在Paxos的算法中找到原型并加以解决。这也正是我们认为Paxos是<br>ZooKeeper的灵魂的原因。当然ZK还有很多属于自己特性的东西：Session, Watcher，Version等等。</p><p>情况二：<br>屁民甲(Client)到某个议员(ZK Server)那里询问(Get)某条法令的情况(ZNode的数据)，议员毫不犹豫的拿出他的记事本(local storage)，查阅法令并告诉他结果，同时声明：我的数据不一定是最新的。你想要最新的数据？没问题，等着，等我找总统Sync一下再告诉你。</p><p>情况三：<br>屁民乙(Client)到某个议员(ZK Server)那里要求政府归还欠他的一万元钱，议员让他在办公室等着，自己将问题反映给了总统，总统询问所有议员的意见，多数议员表示欠屁民的钱一定要还，于是总统发表声明，从国库中拿出一万元还债，国库总资产由100万变成99万。屁民乙拿到钱回去了(Client函数返回)</p><h2 id="2-ZooKeeper集群分布式安装"><a href="#2-ZooKeeper集群分布式安装" class="headerlink" title="2 ZooKeeper集群分布式安装"></a>2 ZooKeeper集群分布式安装</h2><h3 id="2-1-四台服务器之间免密登录"><a href="#2-1-四台服务器之间免密登录" class="headerlink" title="2.1    四台服务器之间免密登录"></a>2.1    四台服务器之间免密登录</h3><p>四台服务器之间互相均可以免密登录<br>a、    首先在四台服务器上都要执行：</p><pre class="line-numbers language-none"><code class="language-none">ssh-keygen  -t  dsa  -P  &#39;&#39;  -f  ~&#x2F;.ssh&#x2F;id_dsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>b、在node1上将node1 的公钥拷贝到authorized_keys中：</p><pre class="line-numbers language-none"><code class="language-none">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c、在node2中将node2的公钥追加到authorized_keys中：</p><pre class="line-numbers language-none"><code class="language-none">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将该文件拷贝给node3：</p><pre class="line-numbers language-none"><code class="language-none">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>d、在node3中将node3的公钥追加到authorized_keys中：</p><pre class="line-numbers language-none"><code class="language-none">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将该文件拷贝给node4：</p><pre class="line-numbers language-none"><code class="language-none">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node4:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>e、在node4中将node4的公钥追加到authorized_keys中：</p><pre class="line-numbers language-none"><code class="language-none">cat  ~&#x2F;.ssh&#x2F;id_dsa.pub  &gt;&gt;  ~&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将该文件拷贝给node1、node2、node3：</p><pre class="line-numbers language-none"><code class="language-none">scp  ~&#x2F;.ssh&#x2F;authorized_keys   node1:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node2:&#x2F;root&#x2F;.ssh&#x2F;scp  ~&#x2F;.ssh&#x2F;authorized_keys   node3:&#x2F;root&#x2F;.ssh&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="2-2-JDK安装环境变量配置"><a href="#2-2-JDK安装环境变量配置" class="headerlink" title="2.2    JDK安装环境变量配置"></a>2.2    JDK安装环境变量配置</h3><p>node1-node4</p><pre class="line-numbers language-none"><code class="language-none">mkdir &#x2F;opt&#x2F;apps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将jdk-8u221-linux-x64.rpm上传到node1/opt/apps<br>将/opt/apps下的jdk.rpm scp到node2、node3、node4的对应目录中</p><pre class="line-numbers language-none"><code class="language-none">scp jdk-8u221-linux-x64.rpm node2:&#x2F;opt&#x2F;appsscp jdk-8u221-linux-x64.rpm node3:&#x2F;opt&#x2F;appsscp jdk-8u221-linux-x64.rpm node4:&#x2F;opt&#x2F;apps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在node1、node2、node3、node4上安装jdk并配置profile文件</p><pre class="line-numbers language-none"><code class="language-none">rpm -ivh jdk-8u221-linux-x64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>node1上修改环境变量</p><pre class="line-numbers language-none"><code class="language-none">vim &#x2F;etc&#x2F;profileexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;defaultexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;binsource &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>将node1的/etc/profile拷贝到node2、node3、node4上并执行. /etc/profile</p><pre class="line-numbers language-none"><code class="language-none">scp &#x2F;etc&#x2F;profile node[234]:&#96;pwd&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-ZooKeeper集群搭建"><a href="#2-3-ZooKeeper集群搭建" class="headerlink" title="2.3    ZooKeeper集群搭建"></a>2.3    ZooKeeper集群搭建</h3><p>a) 将ZooKeeper.tar.gz上传到node2<br>b) 解压到/opt</p><pre class="line-numbers language-none"><code class="language-none">tar -zxvf ZooKeeper-3.4.6.tar.gz -C &#x2F;opt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>c) 配置环境变量：</p><pre class="line-numbers language-none"><code class="language-none">export ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.6export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$ZOOKEEPER_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后./etc/profile让配置生效<br>最后将该文件scp到node3和node4上，并分别./etc/profile让配置生效</p><pre class="line-numbers language-none"><code class="language-none">scp &#x2F;etc&#x2F;profile bk3:&#x2F;etc&#x2F;scp &#x2F;etc&#x2F;profile bk4:&#x2F;etc&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>d) 到$ZooKeeper_HOME/conf下<br>复制zoo_sample.cfg为zoo.cfg</p><pre class="line-numbers language-none"><code class="language-none">cp zoo_sample.cfg  zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>e) 编辑zoo.cfg<br>补充：参数说明<br><strong>tickTime</strong>=2000 #发送心跳的间隔时间，单位：毫秒<br><strong>dataDir</strong>=/opt/zookeeper-3.4.6/data #ZooKeeper保存数据的目录<br><strong>dataLogDir</strong>=/var/bjsxt/zookeeper/datalog #日志目录<br><strong>clientPort</strong>=2181<br><strong>initLimit</strong>=5 （follower或obsever 初始化连接leader最大间隔数）<br><strong>syncLimit</strong>=2 （leader和follower之间发送信息，请求和应答时间长度）<br>    server.1=server2:2881:3881<br>    server.2=server3:2881:3881<br>    server.3=node4:2881:3881  #observer（表示对应节点不参与投票）<br><strong>clientPort</strong>：客户端连接 ZooKeeper 服务器的端口，ZooKeeper  会监听这个端口，接受客户端的访问请求。<br><strong>initLimit</strong>： 这个配置项是用来配置 ZooKeeper 接受客户端（这里所说的客户端不是用户连接ZooKeeper服务器的客户端，而是 ZooKeeper 服务器集群中follower或observer连接到 Leader的Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5 个心跳的时间（也就是 tickTime）长度后 ZooKeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10秒<br><strong>syncLimit</strong>：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime 的时间长度，总的时间长度就是 4*2000=8 秒<br><strong>server.A=B：C：D</strong>：其 中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的ip地址；C 表示的是这个服务器与集群中的Leader服务器交换信息的端口；D表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于B都是一样，所以不同的ZooKeeper实例通信端口号不能一样，所以要给它们分配不同的端口号</p><p>添加如下行：</p><pre class="line-numbers language-none"><code class="language-none">server.1&#x3D;node2:2881:3881server.2&#x3D;node3:2881:3881server.3&#x3D;node4:2881:3881<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>修改</p><pre class="line-numbers language-none"><code class="language-none">dataDir&#x3D;&#x2F;opt&#x2F;ZooKeeper-3.4.6&#x2F;data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>f) 创建/opt/ZooKeeper-3.4.6/data目录，并在该目录下放一个文件：myid<br>      在myid中写下当前ZooKeeper的编号</p><pre class="line-numbers language-none"><code class="language-none">mkdir &#x2F;opt&#x2F;zookeeper-3.4.6&#x2F;datamkdir &#x2F;var&#x2F;bjsxt&#x2F;zookeeper&#x2F;datalogecho 1 &gt; &#x2F;opt&#x2F;zookeeper-3.4.6&#x2F;data&#x2F;myid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>g)将配置好ZooKeeper拷贝到node3、node4上</p><pre class="line-numbers language-none"><code class="language-none">scp -r ZooKeeper-3.4.6&#x2F; node3:&#x2F;opt&#x2F;scp -r ZooKeeper-3.4.6&#x2F; node4:&#x2F;opt&#x2F;#配置zookeeper环境变量export ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeper-3.4.6export PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>h) 在node3和node4上分别修改：myid<br> node3</p><pre class="line-numbers language-none"><code class="language-none">echo 2 &gt; &#x2F;opt&#x2F;ZooKeeper-3.4.6&#x2F;data&#x2F;myid2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>node4</p><pre class="line-numbers language-none"><code class="language-none">echo 3 &gt; &#x2F;opt&#x2F;ZooKeeper-3.4.6&#x2F;data&#x2F;myid3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>i) 分别启动ZooKeeper</p><pre class="line-numbers language-none"><code class="language-none">zkServer.sh start 启动zkzkServer.sh stop  停止zkzkServer.sh status  查看zk状态zkServer.sh start|stop|status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>j) 关闭ZooKeeper</p><pre class="line-numbers language-none"><code class="language-none">zkServer.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>l) 连接ZooKeeper</p><pre class="line-numbers language-none"><code class="language-none">zkCli.sh     node2、node3、node4都可以<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>m) 退出zkCli.sh命令</p><pre class="line-numbers language-none"><code class="language-none">quit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提供集群模式的服务:<br>原子性<br>    准确的反馈成功或失败<br>一致性<br>    每个server都有统一的数据视图<br>可用性<br>    节点故障不影响使用    少于一半的宕机，没问题<br>网络分区/脑裂：过半通过<br>谁年龄大myid：<br>    1 2 3  （同时启动）<br>    1 2   3   （逐一启动）<br>谁数据新：<br>    3 3 4  事务id（zxid）大的当领导</p><p> 3台机器 挂一台    2&gt;3/2<br> 5台机器 挂了1台 4&gt;5/2（可以工作） 挂3台 2！&gt;5/2（集群无法工作）<br>顺序性：FIFO 使用消息队列先进先出</p><p>主从模型<br>    Leader  Follower+<br>    一写多读<br>        Leader负责增删改，Follower负责读和投票</p><p>集群状态<br>    选举模式  安其内<br>    广播模式  壤其外<br>Server状态<br>    LOOKING：当前Server不知道leader是谁，正在搜寻<br>    LEADING：当前Server即为选举出来的leader<br>    FOLLOWING：leader已经选举出来，当前Server与之同步<br>主从分工<br>    领导者（leader）<br>            负责进行投票的发起和决议，更新系统状态，（增删改）<br>    学习者（learner）<br>        包括跟随者（follower）和观察者（observer），follower用于接受客户端请求并向客户端返回结果，在操作过程中参与投票<br>    Observer<br>        可以接受客户端连接，将写请求转发给leader，但observer不参加投票过程，只同步leader的状态，observer的目的是为了扩展系统，提高读取速度<br>    客户端（client）<br>            请求发起方</p><h2 id="3-ZooKeeper进阶"><a href="#3-ZooKeeper进阶" class="headerlink" title="3    ZooKeeper进阶"></a>3    ZooKeeper进阶</h2><h3 id="3-1-Znode数据结构"><a href="#3-1-Znode数据结构" class="headerlink" title="3.1    Znode数据结构"></a>3.1    Znode数据结构</h3><p><a href="https://ibb.co/ZKv8KtF">Znode数据结构</a></p><ol><li>   ZK有一个最开始的节点 /</li><li>   ZK的节点叫做znode节点</li><li>   每个znode节点都可存储数据</li><li>   每个znode节点（临时节点除外）都可创建自己的子节点</li><li>   多个znode节点共同形成了znode树</li><li>   Znode树的维系实在内存中，目的是供用户快速的查询</li><li>   每个znode节点都是一个路径（通过路径来定位这个节点）</li><li>   每个路径名都是唯一的。</li></ol><h4 id="3-1-1-目录结构"><a href="#3-1-1-目录结构" class="headerlink" title="3.1.1    目录结构"></a>3.1.1    目录结构</h4><p>层次的，目录型结构，便于管理逻辑关系<br>znode信息<br>    包含最大1MB的数据信息<br>    记录了zxid等元数据信息</p><h4 id="3-1-2-节点类型"><a href="#3-1-2-节点类型" class="headerlink" title="3.1.2    节点类型"></a>3.1.2    节点类型</h4><p>znode有两种类型，临时的（ephemeral）和持久的（persistent）<br>znode支持序列SEQUENTIAL<br>    临时znode<br>        客户端会话结束时，ZooKeeper将该临时znode删除，临时znode没有子节点<br>    持久znode<br>        不依赖于客户端会话，只有当客户端明确要删除该持久znode时才会被删除<br>    znode的类型在创建时确定并且之后不能再修改</p><pre><code>有序znode节点被分配唯一单调递增的整数。    比如：客户端创建有序znode，路径为/task/task-，则ZooKeeper为其分配序号1，并追加到znode节点：    /task/task-000000001。有序znode节点唯一，同时也可根据该序号查看znode创建顺序。</code></pre><p>znode有四种形式的目录节点<br>    PERSISTENT：普通持久<br>    EPHEMERAL：普通临时<br>    PERSISTENT_SEQUENTIAL：顺序持久<br>    EPHEMERAL_SEQUENTIAL：顺序临时</p><p>要想执行以下指令，需要先启动zk服务器端，再启动zk客户端<br>    ./zkServer.sh start:启动zk服务器端<br>    ./zkCli.sh：启动zk客户端</p><h3 id="3-2-ZK客户端命令行操作"><a href="#3-2-ZK客户端命令行操作" class="headerlink" title="3.2    ZK客户端命令行操作"></a>3.2    ZK客户端命令行操作</h3><table><thead><tr><th>指令</th><th>示例</th></tr></thead><tbody><tr><td>ls查看指令</td><td>ls /</td></tr><tr><td>create创建节点指令，注意，在创建节点时，要分配初始数据。</td><td>create创建节点指令，注意，在创建节点时，要分配初始数据。    create /zk01/ hellocreate /zk02 ‘’</td></tr><tr><td>get查看节点数据指令；<br>hello  数据 <br>cZxid = 0x2 <br>ctime = Mon May 15 05:58:32 PDT 2017 <br>创建节点的时间戳 mZxid = 0x2 <br>mtime = Mon May 15 05:58:32 PDT 2017 <br>修改此节点数据的最新时间戳 <br>pZxid = 0x2 cversion = 0 dataVersion = 0 <br>数据版本号，每当数据发生变化，版本号递增1 <br>aclVersion = 0 ephemeralOwner = 0x0 <br>dataLength = 5数据大小  <br>numChildren = 0子节点个数</td><td>get /zk01</td></tr><tr><td>set更新节点数据指令(执行后mtime、dataVersion肯定会放生变化，dataLength可能会变化)</td><td>set /zk01 hellozk</td></tr><tr><td>delete删除节点</td><td>delete /zk01</td></tr><tr><td>create指令补充：<br>1.    创建子节点 <br> 2.Zk节点分四种类型:分别是：：普通持久节点:普通临时节点：创建此临时节点的客户端失去和zk连接后，此节点消失.zk是通过临时节点监控哪个服务器挂掉的。  <br>  顺序持久节点：会根据用户指定的节点路径，自动分配一个递增的顺序号。（顺序节点实现分布式锁的效果，服务器1抢到zk05分配zk050001，服务器2抢到zk05分配zk050002） <br>  顺序临时节点：</td><td>1.create /zk01/node01 hello  <br>2.<br>    2.1．create /zk01 hello <br>    2.2. create –e /zk02 abc  <br>    2.3.create –s /zk03 abc  <br>    2.4.create –s -e /zk05 abcd zk050000000003 再创建一个就是：zk050000000004</td></tr></tbody></table><h3 id="3-3-ZooKeeper会话"><a href="#3-3-ZooKeeper会话" class="headerlink" title="3.3    ZooKeeper会话"></a>3.3    ZooKeeper会话</h3><ol><li>客户端通过TCP协议与独立服务器或者一个集群中的某个服务器建立会话连接。</li><li>会话提供顺序保障，即同一个会话中的请求以FIFO的顺序执行。如果客户端有多个并发会话，FIFO顺序在多个会话之间未必能够保持。</li><li>如果连接的Server出现问题，在没有超过Timeout时间时，可以连接其他节点。ZooKeeper客户端透明地转移一个会话到不同的服务器。</li><li>同一session期内的特性不变</li><li>当一个会话因某种原因终止，在这个会话期间创建的临时节点将会消失。<strong>Session是由谁来创建的？</strong>Leader：产生一个唯一的session，放到消息队列，让所有server知道过半机制：保证session创建成功或者失败</li></ol><h3 id="3-4-事件监听原理刨析"><a href="#3-4-事件监听原理刨析" class="headerlink" title="3.4    事件监听原理刨析"></a>3.4    事件监听原理刨析</h3><p>客户端轮询指定节点下的数据<br>通过网络轮询，代价很大<br><a href="https://ibb.co/nbKSTt5">监听机制</a></p><p>基于通知（notification）的机制：<br><a href="https://ibb.co/twrrw6M">图例</a><br>    客户端向ZooKeeper注册需要接收通知的znode，<br>通过对znode设置监视点（watch）来接收通知。监视点是一个单次触发的操作，意即监视点会触发一个通知。<br>    为了接收多个通知，客户端必须在每次通知后设置一个新的监视点</p><p>事件监听Watcher<br>    Watcher 在 ZooKeeper 是一个核心功能，Watcher 可以监控目录节点的数据变化以及子目录的变化，一旦这些状态发生变化，服务器就会通知所有设置在这个目录节点上的Watcher，从而每个客户端都很快知道它所关注的目录节点的状态发生变化，而做出相应的反应。<br>    可以设置观察点的操作：exists,getChildren,getData<br>    可以触发观察的操作：create,delete,setData</p><p>回调client方法<br>业务核心代码在哪里？<br>     client</p><h3 id="3-5-广播模式刨析"><a href="#3-5-广播模式刨析" class="headerlink" title="3.5    广播模式刨析"></a>3.5    广播模式刨析</h3><p><a href="https://ibb.co/pjfML9k">广播机制</a><br>ZooKeeper的核心是原子广播，这个机制保证了各个server之间的信息同步。实现这个机制的协议叫做ZAB协议。<br>ZAB协议有两种模式：<br>1.恢复模式：当服务启动或者在领导者崩溃后，ZAB就进入了恢复模式。当领导者被选举出来，且大多数server的完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和follower以及observer具有相同的系统状态<br>2.广播模式<br>广播模式需要保证proposal被按顺序处理，因此zk采用了递增的事务id号(zxid)来保证。所有的提议(proposal)都在被提出的时候加上了zxid(比如：0x1000000300000002)。<br>epoch也称为纪元数字。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，低32位是个递增计数。</p><h3 id="3-6-Zookeeper集群的特点"><a href="#3-6-Zookeeper集群的特点" class="headerlink" title="3.6    Zookeeper集群的特点"></a>3.6    Zookeeper集群的特点</h3><p><a href="https://ibb.co/B38gPCC">特点</a><br>•    角色模型<br>    –    集群状态（可用/不可用）<br>    –    主从分工<br>•    攘其外：<br>    –    统一视图<br>        •    会话session<br>        •    数据模型Znode<br>            –    目录结构<br>            –    节点类型<br>    –    事件监听Watcher<br>•    原理：<br>    –    原子消息广播协议ZAB<br>    •    paxos<br>        –    journalnode<br>        –    Sentinel (redis 哨兵）<br>        –    ZooKeeper   ZAB<br>    •    zxid ,myid：<br>    •    ZXID:epoch+ID<br>    –    广播模式原理<br>    –    恢复模式原理：无主模型：zab： zxid ,myid</p><p>无主，无服务。选举过程耗时在200ms之内，一般情况下ZooKeeper恢复服务时间间隔不超过200ms</p><h3 id="3-7-ZK常见的应用场景"><a href="#3-7-ZK常见的应用场景" class="headerlink" title="3.7    ZK常见的应用场景"></a>3.7    ZK常见的应用场景</h3><ol><li>   分布式环境下的统一命名服务<br><a href="https://ibb.co/dg67P75">示例</a></li><li> 分布式环境下的配置管理<br><a href="https://ibb.co/8jv8y1x">示例</a></li><li>   数据发布/订阅</li><li>   分布式环境下的分布式锁</li><li>   集群管理问题</li></ol><h2 id="4-ZK-API实战"><a href="#4-ZK-API实战" class="headerlink" title="4    ZK API实战"></a>4    ZK API实战</h2><h3 id="4-1-IDEA环境搭建"><a href="#4-1-IDEA环境搭建" class="headerlink" title="4.1    IDEA环境搭建"></a>4.1    IDEA环境搭建</h3><ol><li>   新建project</li><li>   将log4j.properties文件拷贝到项目的src目录</li><li>   项目的根目录新建lib文件夹，将jar包拷贝到该目录下。</li><li>   File-&gt; -&gt;Libaries</li><li>   新建包</li></ol><h3 id="4-2-创建ZooKeeper客户端"><a href="#4-2-创建ZooKeeper客户端" class="headerlink" title="4.2    创建ZooKeeper客户端"></a>4.2    创建ZooKeeper客户端</h3><p>在该包下新建类ZooKeeperTest<br>略&gt;&gt; 该部分为java 不会  》》 可用Python代替</p><p>python可以用 KazooClient 模块实现功能<br><a href="https://www.helloworld.net/p/7482175713">代码示例</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> kazoo<span class="token punctuation">.</span>client <span class="token keyword">import</span>  KazooClient<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZooKeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx</title>
      <link href="/2021/12/21/nginx/"/>
      <url>/2021/12/21/nginx/</url>
      
        <content type="html"><![CDATA[<h2 id="Nginx-–-负载均衡"><a href="#Nginx-–-负载均衡" class="headerlink" title="Nginx – 负载均衡"></a>Nginx – 负载均衡</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h3><h4 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h4><ol><li>Nginx (“engine x”) 是一个高性能的 静态HTTP 和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。</li><li>第一个公开版本0.1.0发布于2004年10月4日。</li><li>其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名</li><li>官方测试nginx能够支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定</li><li>2011年6月1日，nginx 1.0.4发布。apache httpd</li><li>Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：新浪、网易、腾讯等。</li></ol><h4 id="1-2-Nginx-和-apache的优缺点"><a href="#1-2-Nginx-和-apache的优缺点" class="headerlink" title="1.2 Nginx 和 apache的优缺点"></a>1.2 Nginx 和 apache的优缺点</h4><h5 id="1-2-1-nginx-相对于-apache的优点"><a href="#1-2-1-nginx-相对于-apache的优点" class="headerlink" title="1.2.1 nginx 相对于 apache的优点"></a>1.2.1 nginx 相对于 apache的优点</h5><ol><li>轻量级，同样起web 服务，比apache 占用更少的内存及资源 </li><li>抗并发，nginx 处理请求是异步非阻塞 <a href="https://zhuanlan.zhihu.com/p/82935440">参考文章</a> 的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能  NIO netty NIO</li><li>高度模块化的设计，编写模块相对简单 </li><li>社区活跃，各种高性能模块出品迅速</li></ol><h5 id="1-2-2-apache-相对于-nginx的优点"><a href="#1-2-2-apache-相对于-nginx的优点" class="headerlink" title="1.2.2 apache 相对于 nginx的优点"></a>1.2.2 apache 相对于 nginx的优点</h5><ol><li>rewrite ，比nginx 的rewrite 强大 </li><li>模块超多，基本想到的都可以找到 </li><li>少bug ，nginx 的bug 相对较多 </li><li>Nginx 配置简洁, Apache 复杂 </li><li>最核心的区别在于apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程</li></ol><h3 id="2-Nginx下载与安装"><a href="#2-Nginx下载与安装" class="headerlink" title="2 Nginx下载与安装"></a>2 Nginx下载与安装</h3><h4 id="2-1-Nginx-下载"><a href="#2-1-Nginx-下载" class="headerlink" title="2.1 Nginx 下载"></a>2.1 Nginx 下载</h4><p><a href="http://nginx.org/">官网下载Nginx软件</a><br>Nginx 官方提供了三个类型的版本：<br>    Mainline Version：主线版，是最新版，但未经过过多的生产测试。<br>    Stable Version：稳定版，生产环境使用版本。<br>    Legacy Version：老版本。<br>下载iStable Version nginx - 1.16.1</p><h4 id="2-2-Nginx-的源码安装"><a href="#2-2-Nginx-的源码安装" class="headerlink" title="2.2 Nginx 的源码安装"></a>2.2 Nginx 的源码安装</h4><h5 id="2-2-1-安装前的准备工作"><a href="#2-2-1-安装前的准备工作" class="headerlink" title="2.2.1 安装前的准备工作"></a>2.2.1 安装前的准备工作</h5><p>克隆一个没有安装其它软件的纯净主机。完成以下配置：<br>1.修改主机名：vim /etc/sysconfig/network</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 ~]# hostname nginx1[root@nginx1 ~]# vim &#x2F;etc&#x2F;sysconfig&#x2F;networkHOSTNAME  nginx1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2.修改网络配置：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33  your hostname <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="2-2-2-安装Nginx"><a href="#2-2-2-安装Nginx" class="headerlink" title="2.2.2 安装Nginx"></a>2.2.2 安装Nginx</h5><ol><li>安装源码编译以及Nginx依赖的库</li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum install gcc gcc-c++ pcre  pcre-devel openssl openssl-devel zlib  zlib-devel vim -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>创建存放源文件的文件夹<br>首先在目录/opt下创建apps目录，用于存放源文件以及解压后的文件</li><li>上传Nginx到2创建的目</li><li>解压 Nginx</li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 apps]# pwd&#x2F;opt&#x2F;apps[root@nginx1 apps]# lsnginx-1.16.1.tar.gz[root@nginx1 apps]# tar -zxvf nginx-1.16.1.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>进入到/opt/apps 目录中的 Nginx 解压包目录，查看 Nginx 的目录<ul><li>其中各个目录中存放的文件作用为：<ul><li>auto：存放 Nginx 自动安装的相关文件</li><li>conf：存放 Nginx 服务器配置文件</li><li>configure：命令，用于对即将安装的软件的配置，完成 Makefile 编译文件的生成</li><li>contrib：存放由其他机构贡献的文档材料</li><li>html：存放 Nginx 欢迎页面</li><li>man：manual，手册，存放 Nginx 帮助文档</li><li>src：存放 Nginx 源码</li></ul></li></ul></li></ul><p>5.生成Makefile<br>    在 Nginx 解压目录下运行 make 命令，用于完成编译。但此时会给出提示：没有指定目标，并且没有发现编译文件 makefile。编译命令 make 需要根据编译文件 makefile 进行编译，所以在编译之前需要先生成编译文件 makefile。使用 configure 命令可以生成该文件。那么，configure 命令需要配置些什么参数呢？使用–help 可以查看到可以使用的参数说明。这些参数可以分为三类：<br>    第一类：基本信息的配置。<br>    第二类：默认没有安装，可以指定安装的模块，使用–with 开头。Nginx 的高扩展性就体现在这里。<br>    第三类：默认已经安装，可以指定卸载的模块，使用–without 开头</p><p>下面是简单配置的命令执行。命令中每一行的最后添加了反斜杠\表示当前命令并未结束，回车不会执行该命令。执行成功后，会给出配置报告。下面以安装对 https 访问协议支持的模块 http_ssl_module 为例。<br>–prefix：用于指定 nginx 的安装目录。注意，安装目录与解压目录不一样。<br>–http_ssl_module：https 访问协议需要安装 Http 安全连接协议模块 SSL（Secure SocketsLayer，安全套接层）。注意，在执行过 configure 命令后并不会立即生成/usr/local/nginx 目录，也不会马上开始安装指定的模块，而仅仅是将命令中指定的参数及默认配置写入到即将要生成的 Makefile文件中</p><p><strong>配置报告以两部分构成：第一部分给出了配置的系统库；第二部分给出了系统配置信息</strong><br>     path prefix：Nginx 安装目录<br>    binary file：Nginx 命令文件<br>    modules path：Nginx 模块存放路径<br>    configuration prefix：Nginx 配置文件存放路径<br>    configuration file：Nginx 配置文件名<br>    pid file：Nginx 的进程 id 文件<br>    error log file：错误日志文件<br>    http access log file：http 访问日志文件；<br>    http xxx：其它 http 请求相关的文件。<br>配置成功后，再次查看 Nginx 解压目录，发现其中多出了一个文件 Makefile。后面的编译就是依靠该文件进行的。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 nginx-1.16.1]# mkdir –p &#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;client[root@nginx1 nginx-1.16.1]# pwd&#x2F;opt&#x2F;apps&#x2F;nginx-1.16.1[root@nginx1 nginx-1.16.1]# .&#x2F;configure \--prefix&#x3D;&#x2F;opt&#x2F;nginx \--sbin-path&#x3D;&#x2F;usr&#x2F;sbin&#x2F;nginx\--conf-path&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf \--error-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log \--http-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log \--pid-path&#x3D;&#x2F;var&#x2F;run&#x2F;nginx&#x2F;nginx.pid \--lock-path&#x3D;&#x2F;var&#x2F;lock&#x2F;nginx.lock \--user&#x3D;nginx \--group&#x3D;nginx \--with-http_ssl_module \--with-http_flv_module \--with-http_stub_status_module \--with-http_gzip_static_module \--http-client-body-temp-path&#x3D;&#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;client&#x2F; \--http-proxy-temp-path&#x3D;&#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;proxy&#x2F; \--http-fastcgi-temp-path&#x3D;&#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;fcgi&#x2F; \--http-uwsgi-temp-path&#x3D;&#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;uwsgi \--http-scgi-temp-path&#x3D;&#x2F;var&#x2F;tmp&#x2F;nginx&#x2F;scgi \--with-pcre  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  <strong>注意： /var/tmp/nginx/client目录需要手动创建</strong><br>也可以使用简单安装，指定安装目录和https访问支持</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">.&#x2F;configure --prefix&#x3D;&#x2F;opt&#x2F;nginx --with-http_ssl_module --with-http_gzip_static_module --error-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;nginx.log --pid-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;pid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li><p>编译安装<br>这是两个命令，make 为编译命令，make install 为安装命令，可以分别执行。这里使用&amp;&amp;将两个命令连接执行，会在前面命令执行成功的前提下才会执行第二个命令。<br>make &amp;&amp; make install</p></li><li><p>nginx  命令随处可用<br>在 Nginx 的安装目录/opt/nginx 中有一个 sbin 目录，其中存放着 nginx 的命令程序nginx。默认情况下，若要使用 nginx 命令，则必须要在/opt/nginx/sbin 目录中，或指定命令路径，使用起来很不方便。为了能够在任意目录下均可直接执行 nginx 命令，可通过以下两种方式完成。<br>方式一 、  修改/etc/profile  文件<br>在/etc/profile 文件最后添加以下内容，将安装目录下的 sbin 目录添加到 PATH 系统环境变量中。然后再重新加载该文件即可。<br>#修改环境变量</p></li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export PATH&#x3D;$PATH:&#x2F;usr&#x2F;sbin&#x2F;nginx  #注意执行文件的位置useradd nginx  #添加用户（默认添加nginx用户组）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>nginx  #启动nginx<br>方式二 、  添加安装的nginx到服务列表：将如下内容添加到/etc/init.d/nginx脚本中，nginx需要具有可执行权限。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 nginx-1.16.1]# vim &#x2F;etc&#x2F;init.d&#x2F;nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="8"><li>修改配置 启动服务<br>修改nginx文件的执行权限</li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">chmod +x nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加该文件到系统服务中去</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">chkconfig --add nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看是否添加成功</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">chkconfig --list nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动，停止，重新装载</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">service nginx start|stop|reload <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置开机启动</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 conf]# chkconfig nginx on[root@nginx1 conf]# chkconfignginx          0:off1:off2:on3:on4:on5:on6:off<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="2-3-Nginx的工作模型"><a href="#2-3-Nginx的工作模型" class="headerlink" title="2.3  Nginx的工作模型"></a>2.3  Nginx的工作模型</h4><h5 id="2-3-1-Master-Worker模式"><a href="#2-3-1-Master-Worker模式" class="headerlink" title="2.3.1    Master-Worker模式"></a>2.3.1    Master-Worker模式</h5><p>1、Nginx 在启动后，会有一个 master 进程和多个相互独立的 worker 进程。<br>2、Master接收来自外界的信号，向各worker进程发送信号，每个进程都有可能来处理这个连接。<br>3、Master进程能监控Worker进程的运行状态，当 worker 进程退出后(异常情况下)，会自动启动新的 worker 进程。</p><h5 id="2-3-2-accept-mutex"><a href="#2-3-2-accept-mutex" class="headerlink" title="2.3.2    accept_mutex"></a>2.3.2    accept_mutex</h5><p>由于所有子进程都继承了父进程的sockfd，那么当连接进来时，所有子进程都将收到通知并“争着”与它建立连接，这就叫“惊群现象”。大量的进程被激活又挂起，只有一个进程可以accept() 到这个连接，这当然会消耗系统资源。Nginx 提供了一个accept_mutex加在accept上的一把共享锁。即每个worker进程在执行accept之前都需要先获取锁，获取不到就放弃执行accept()。有了这把锁之后，同一时刻，就只会有一个进程去accpet()，这样就不会有惊群问题了。</p><p>当一个worker进程在accept()这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，完成一个完整的请求。一个请求，完全由worker进程来处理，而且只能在一个worker进程中处理</p><h5 id="2-3-3-为什么使用进程不使用线程"><a href="#2-3-3-为什么使用进程不使用线程" class="headerlink" title="2.3.3 为什么使用进程不使用线程"></a>2.3.3 为什么使用进程不使用线程</h5><p>1、节省锁带来的开销。每个worker进程都是独立的进程，不共享资源，不需要加锁。同时在编程以及问题查上时，也会方便很多。<br>2、独立进程，减少风险。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快重新启动新的worker进程。当然，worker进程的也能发生意外退出</p><h5 id="2-3-4-如何处理并发请求"><a href="#2-3-4-如何处理并发请求" class="headerlink" title="2.3.4 如何处理并发请求"></a>2.3.4 如何处理并发请求</h5><p>每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker不会这么傻等着，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多，这就是几个进程就能解决高并发的秘密所在</p><h4 id="2-4-Nginx参数详解"><a href="#2-4-Nginx参数详解" class="headerlink" title="2.4  Nginx参数详解"></a>2.4  Nginx参数详解</h4><h5 id="2-4-1-nginx-conf配置文件全览"><a href="#2-4-1-nginx-conf配置文件全览" class="headerlink" title="2.4.1 nginx.conf配置文件全览"></a>2.4.1 nginx.conf配置文件全览</h5><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token comment">#号是注释。</span><span class="token comment">#---全局块开始----</span><span class="token comment">#user  nobody;</span><span class="token directive"><span class="token keyword">worker_processes</span>  <span class="token number">1</span></span><span class="token punctuation">;</span><span class="token comment">#error_log  logs/error.log;</span><span class="token comment">#error_log  logs/error.log  notice;</span><span class="token comment">#error_log  logs/error.log  info;</span><span class="token comment">#pid        logs/nginx.pid;</span><span class="token comment">#----全局块结束----</span><span class="token comment">#====events块开始====</span><span class="token directive"><span class="token keyword">events</span></span> <span class="token punctuation">&#123;</span><span class="token directive"><span class="token keyword">worker_connections</span>  <span class="token number">1024</span></span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">#====events块结束====</span><span class="token comment">#****http块开始****</span><span class="token directive"><span class="token keyword">http</span></span> <span class="token punctuation">&#123;</span><span class="token directive"><span class="token keyword">include</span>       mime.types</span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">default_type</span>  application/octet-stream</span><span class="token punctuation">;</span><span class="token comment">#log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '</span><span class="token comment">#'$status $body_bytes_sent "$http_referer" '</span>......<span class="token punctuation">&#125;</span><span class="token comment">#****http块结束****</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>nginx由三部分组成：</p><ul><li>第一部分：全局块<br> 从配置文件开始到events之间的内容，主要会设置一些影响nginx服务器整体运行的配置命令。主要包括配置运行Nginx服务器的用户（组）、允许生成的worker process数，进程PID存放路径、日志存放路径和类型以及配置文件的引入等</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#user  nobody; worker_processes  1; #error_log  logs&#x2F;error.log;#error_log  logs&#x2F;error.log  notice;#error_log  logs&#x2F;error.log  info;#pid        logs&#x2F;nginx.pid;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>worker_processes是Nginx服务器并发处理服务的关键配置，值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约。<br>error_log配置nginx日志文件的全路径名<br>pid配置进程PID存放路径</p><ul><li><p>第二部分：events块</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">events</span></span> <span class="token punctuation">&#123;</span>   <span class="token directive"><span class="token keyword">worker_connections</span>  <span class="token number">1024</span></span><span class="token punctuation">;</span>   <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>events块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多work process下的网络连接进行序列化，是否允许同时接受多个网络连接，选取哪种事件驱动模型来处理连接请求，每个work process可以同时支持的最大连接数等。<br>上述的例子表示每个work process支持的最大连接数为1024。这部分的配置对Nginx的性能影响比较大，在实际中应该灵活配置</p></li><li><p>第三部分 http块{ }<br>Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：http块也可以包括http全局块、server块</p><ul><li>http全局块<br>http全局块配置的指令包括文件引入、MIME-TYPE定义、连接超时时间、单链接请求数上限等<pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">http</span></span> <span class="token punctuation">&#123;</span>       <span class="token directive"><span class="token keyword">include</span>       mime.types</span><span class="token punctuation">;</span>           <span class="token directive"><span class="token keyword">default_type</span>  application/octet-stream</span><span class="token punctuation">;</span>           <span class="token comment">#log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '</span>           <span class="token comment">#                  '$status $body_bytes_sent "$http_referer" '</span>       <span class="token comment">#                  '"$http_user_agent" "$http_x_forwarded_for"';</span>           <span class="token comment">#access_log  logs/access.log  main;</span>           <span class="token directive"><span class="token keyword">sendfile</span>        <span class="token boolean">on</span></span><span class="token punctuation">;</span>           <span class="token comment">#tcp_nopush     on;</span>           <span class="token comment">#keepalive_timeout  0;</span>       <span class="token directive"><span class="token keyword">keepalive_timeout</span>  <span class="token number">65</span></span><span class="token punctuation">;</span><span class="token comment">#连接超时时间</span>           <span class="token comment">#gzip  on;#是否启动压缩</span>           <span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>           ......   <span class="token punctuation">&#125;</span>   <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>server块</p><pre><code>  这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。        每个http块可以包括多个server块，而每个server块就相当于一个虚拟主机。而每个server块也分为全局server块，以及可以同时包含多个location块</code></pre>  <pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token comment">#gzip  on;</span><span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span><span class="token directive"><span class="token keyword">listen</span>       <span class="token number">80</span></span><span class="token punctuation">;</span><span class="token comment">#监听的端口号</span><span class="token directive"><span class="token keyword">server_name</span>  localhost</span><span class="token punctuation">;</span><span class="token comment">#监听的域名</span><span class="token comment">#charset koi8-r;</span><span class="token comment">#access_log  logs/host.access.log  main;</span><span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span> <span class="token comment">#路径中包含 /</span><span class="token directive"><span class="token keyword">root</span>   html</span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">index</span>  index.html index.htm</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">#error_page  404              /404.html;</span><span class="token comment"># redirect server error pages to the static page /50x.html</span><span class="token directive"><span class="token keyword">error_page</span>   <span class="token number">500</span> <span class="token number">502</span> <span class="token number">503</span> <span class="token number">504</span>  /50x.html</span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">location</span> = /50x.html</span> <span class="token punctuation">&#123;</span><span class="token directive"><span class="token keyword">root</span>   html</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment"># proxy the PHP scripts to Apache listening on 127.0.0.1:80</span><span class="token comment">#location ~ \.php$ &#123;</span><span class="token comment">#    proxy_pass   http://127.0.0.1;</span><span class="token comment">#&#125;</span><span class="token comment"># pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span><span class="token comment">#</span><span class="token comment">#location ~ \.php$ &#123;</span><span class="token comment">#    root           html;</span><span class="token comment">#    fastcgi_pass   127.0.0.1:9000;</span><span class="token comment">#    fastcgi_index  index.php;</span><span class="token comment">#    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</span><span class="token comment">#    include        fastcgi_params;</span><span class="token comment">#&#125;</span><span class="token comment"># deny access to .htaccess files, if Apache's document root</span><span class="token comment"># concurs with nginx's one</span><span class="token comment">#</span><span class="token comment">#location ~ /$.ht &#123;</span><span class="token comment">#    deny  all;</span><span class="token comment">#&#125;</span>  <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><ul><li><strong>全局server块</strong><pre><code>      最常见的配置是本虚拟主机的监听配置和本虚拟主机的名称或IP配置   **location块**  --- 网址转发（请求出口）</code></pre>一个server块可以配置多个location块。<br>这块的主要作用是基于Nginx服务器接受到的请求字符串（例如 server_name/uri-string）,对虚拟主机名称（也可以是IP别名）之外的字符串（列如        前面的/uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行</li></ul><h5 id="2-4-2-工作模式与连接上限"><a href="#2-4-2-工作模式与连接上限" class="headerlink" title="2.4.2 工作模式与连接上限"></a>2.4.2 工作模式与连接上限</h5><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token comment">#user  nobody;</span><span class="token directive"><span class="token keyword">worker_processes</span>  <span class="token number">1</span></span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">events</span></span> <span class="token punctuation">&#123;</span><span class="token directive"><span class="token keyword">use</span> epoll</span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">worker_connections</span> <span class="token number">1024</span></span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>用户与工作进程</li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#user  nobody;worker_processes  1;[root@nginx1 conf]# ps aux |grep nginxroot       1170  0.0  0.0  22568   680 ?        Ss   09:14   0:00 nginx: master process &#x2F;opt&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.confnobody     1171  0.0  0.1  23020  1288 ?        S    09:14   0:00 nginx: worker process                              root       1174  0.0  0.0 103264   876 pts&#x2F;0    S+   09:14   0:00 grep nginx[root@nginx1 conf]# ps aux |grep nginxroot       1170  0.0  0.0  22568   680 ?        Ss   09:14   0:00 nginx: master process &#x2F;opt&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.confnobody     1171  0.0  0.1  23020  1288 ?        S    09:14   0:00 nginx: worker process                               [root@nginx1 conf]# id nobodyuid&#x3D;99(nobody) gid&#x3D;99(nobody) groups&#x3D;99(nobody)[root@nginx1 conf]# cat &#x2F;etc&#x2F;passwdroot:x:0:0:root:&#x2F;root:&#x2F;bin&#x2F;bash……nobody:x:99:99:Nobody:&#x2F;:&#x2F;sbin&#x2F;nologin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>use epoll</li></ol><ul><li>参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。<br> uname -a :查看服务器系统相关的信息</li></ul><ol start="3"><li>worker_connections  1024<br>单个后台worker process进程的最大并发链接数。<br>并发总数是 worker_processes 和 worker_connections 的乘积<br>  即 max_clients = worker_processes * worker_connections<br>在设置了反向代理的情况下，max_clients=worker_processes * worker_connections / 4<br>Q:为什么上面反向代理要除以4，应该说是一个经验值<br>A:worker_connections 值的设置跟物理内存大小有关;因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数</li></ol><h5 id="2-4-3-开启零拷贝"><a href="#2-4-3-开启零拷贝" class="headerlink" title="2.4.3 开启零拷贝"></a>2.4.3 开启零拷贝</h5><p>sendfile实际上是 Linux2.0+以后的推出的一个系统调用，web服务器可以通过调整自身的配置来决定是否利用 sendfile这个系统调用。先来看一下不用sendfile的传统网络传输过程</p><h5 id="2-4-4-keepalive-timeout"><a href="#2-4-4-keepalive-timeout" class="headerlink" title="2.4.4 keepalive_timeout"></a>2.4.4 keepalive_timeout</h5><p>测试时改为0,便于看出负载切换的效果，部署到生产前进行优化来提高效率</p><h5 id="2-4-5-是否启用压缩"><a href="#2-4-5-是否启用压缩" class="headerlink" title="2.4.5 是否启用压缩"></a>2.4.5 是否启用压缩</h5><p>压缩可以有效减少文件的大小，有利于网络传输</p><h5 id="2-4-6-autoindex"><a href="#2-4-6-autoindex" class="headerlink" title="2.4.6 autoindex"></a>2.4.6 autoindex</h5><p>autoindex on; #开启目录列表访问，合适下载服务器，默认关闭</p><h5 id="2-4-7-nginx虚拟主机演示"><a href="#2-4-7-nginx虚拟主机演示" class="headerlink" title="2.4.7 nginx虚拟主机演示"></a>2.4.7 nginx虚拟主机演示</h5><p>虚拟主机，就是将一台物理服务器虚拟为多个服务器来使用，从而实现在一台服务器上配置多个站点，即可以在一台物理主机上配置多个域名。Nginx 中，一个 server 标签就是一台虚拟主机，配置多个 server 标签就虚拟出了多台主机。</p><p><strong>Nginx 虚拟主机的实现方式有两种：</strong>域名虚拟方式与端口虚拟方式。</p><ol><li>域名虚拟方式是指不同的虚拟机使用不同的域名，通过不同的域名虚拟出不同的主机；</li><li>端口虚拟方式是指不同的虚拟机使用相同的域名不同的端口号，通过不同的端口号虚拟出不同的主机。基于端口的虚拟方式不常用<br><a href="https://ibb.co/qY4LS49">示例</a></li></ol><ol><li>   修改nginx.conf文件</li></ol><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">gzip</span>  <span class="token boolean">on</span></span><span class="token punctuation">;</span><span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>   <span class="token directive"><span class="token keyword">listen</span>  <span class="token number">80</span></span><span class="token punctuation">;</span>   <span class="token directive"><span class="token keyword">server_name</span> www.sxthenhao.com</span><span class="token punctuation">;</span>   <span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span>       <span class="token directive"><span class="token keyword">root</span> /mnt</span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">autoindex</span> <span class="token boolean">on</span></span><span class="token punctuation">;</span>   <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>    <span class="token directive"><span class="token keyword">listen</span>       <span class="token number">80</span></span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">server_name</span> www.123.com</span><span class="token punctuation">;</span>    <span class="token comment">#charset koi8-r;</span>    <span class="token comment">#access_log  logs/host.access.log  main;</span>    <span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span>        <span class="token directive"><span class="token keyword">root</span>   html</span><span class="token punctuation">;</span>        <span class="token directive"><span class="token keyword">index</span>  index.html index.htm</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ps： vim 删除小技巧： 命令行模式下 .,-num d  删除光标位置 到 倒数第num行内容</p><p>重新加载nginx</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 conf]# service nginx reload#centos7 重启方式[root@nginx1 conf]# sbin&#x2F;nginx -s reload<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>   修改本机hosts文件（C:\Windows\System32\drivers\etc）</li></ol><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">193.192.168.20.11 nginx1 www.123.com  www.sxthenhao.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>测试访问</li></ol><h5 id="2-4-8-日志配置"><a href="#2-4-8-日志配置" class="headerlink" title="2.4.8 日志配置"></a>2.4.8 日志配置</h5><p>作为日志服务器</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 logs]# pwd&#x2F;opt&#x2F;nginx&#x2F;logs [root@nginx1 logs]# tail -f access.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>本地浏览器访问：<a href="http://www.123.com/2019-12-03maxwd19">http://www.123.com/2019-12-03maxwd19</a><br>先不管404的问题，查看日志多了一条记录</p><p>当然日志格式我们也可以自定义<br>access_log配置http下，多server公用，配置http-&gt;某server下，仅对该server使用。</p><h5 id="2-4-9-Location（重点）"><a href="#2-4-9-Location（重点）" class="headerlink" title="2.4.9 Location（重点）"></a>2.4.9 Location（重点）</h5><p>[参考](参考：<br><a href="http://tengine.taobao.org/nginx_docs/cn/docs/http/ngx_http_core_module.html">http://tengine.taobao.org/nginx_docs/cn/docs/http/ngx_http_core_module.html</a><br>)<br>语法:</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">location</span> [ = | ~ | ~* | ^~ ] uri</span> <span class="token punctuation">&#123;</span> ... <span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">location</span> @name</span> <span class="token punctuation">&#123;</span> ... <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>默认值    -<br>上下文    server, location</p><p>示例：</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">location</span> = /</span> <span class="token punctuation">&#123;</span>    [ configuration A ]<span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span>    [ configuration B ]<span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">location</span> /documents/</span> <span class="token punctuation">&#123;</span>    [ configuration C ]<span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">location</span> ^~ /images/</span> <span class="token punctuation">&#123;</span>    [ configuration D ]<span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">location</span> ~* \.(gif|jpg|jpeg)$</span> <span class="token punctuation">&#123;</span>     [ configuration E ] <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>请求“/”匹配配置A，<br>请求“/index.html”匹配配置B，<br>请求“/documents/document.html”匹配配置C，<br>请求“/images/1.gif”匹配配置D，<br>请求“/documents/1.jpg”匹配配置E。<br><a href="https://ibb.co/4ZdzsLN">look</a><br><a href="https://ibb.co/swGSd4X">ll</a><br><a href="https://ibb.co/q71KxRq">lll</a></p><p>操作步骤：</p><ol><li><p>修改nginx.conf配置文件</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx">    <span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>       <span class="token directive"><span class="token keyword">listen</span>  <span class="token number">80</span></span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">server_name</span> www.sxthenhao.com</span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">access_log</span>   logs/myfmt.log  myfmt</span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span>           <span class="token directive"><span class="token keyword">root</span> /mnt</span><span class="token punctuation">;</span>           <span class="token directive"><span class="token keyword">autoindex</span> <span class="token boolean">on</span></span><span class="token punctuation">;</span>       <span class="token punctuation">&#125;</span>       <span class="token directive"><span class="token keyword">location</span> /ooxx</span> <span class="token punctuation">&#123;</span>          <span class="token directive"><span class="token keyword">proxy_pass</span> http://192.168.40.102./</span><span class="token punctuation">;</span><span class="token comment">#带上/访问该url对应的首页，</span><span class="token comment">#不带/ 访问http://192.168.20.92/ooxx</span>       <span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p> 重新加载nginx –!ser –在history下使用 –不推荐</p></li><li><p> 访问测试 – <a href="http://www.sxthenhao.com/ooxx">http://www.sxthenhao.com/ooxx</a></p></li><li><p> 修改nginx.conf</p></li></ol><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">location</span> /ooxx</span> <span class="token punctuation">&#123;</span>    <span class="token directive"><span class="token keyword">proxy_pass</span> http://www.baidu.com/</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> <span class="token comment">#此情况 nginx不会记录在浏览器的操作  使用https会被记录</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>重启nginx</li><li>[root@nginx1 conf]# !ser<br>如果重启没有问题，直接跳步骤7.<br>如果出现找不到域名，也就是访问不到域名解析服务器：</li></ol><ol start="7"><li>   访问测试<a href="http://www.sxthenhao.com/ooxx">http://www.sxthenhao.com/ooxx</a></li></ol><h5 id="2-4-10-Bug-https-protocol-requires-SSL-support-in"><a href="#2-4-10-Bug-https-protocol-requires-SSL-support-in" class="headerlink" title="2.4.10    Bug https protocol requires SSL support in"></a>2.4.10    Bug https protocol requires SSL support in</h5><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 conf]# service nginx reloadnginx: [emerg] https protocol requires SSL support in &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.conf:45nginx: configuration file &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.conf test failed<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>当初编译的时候没有启用SSL支持，在配置反向代理到 https的网站时，编辑配置文件报错，无法启动nginx。<br>解决办法：先将nginx.conf备份/root/目录下，删除/opt/nginx和/opt/apps/<br>nginx-1.16.1,然后在解压一份，最后编译安装</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@nginx1 nginx-1.16.1]# .&#x2F;configure --prefix&#x3D;&#x2F;opt&#x2F;nginx --with-http_ssl_module[root@nginx1 nginx-1.16.1]# make &amp;&amp; make install[root@nginx1 nginx-1.16.1]# cd &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;[root@nginx1 conf]# cp &#x2F;root&#x2F;nginx.conf  .&#x2F;cp: overwrite &#96;.&#x2F;nginx.conf&#39;? yes[root@nginx1 conf]# service nginx reloadnginx: the configuration file &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.conf syntax is oknginx: configuration file &#x2F;opt&#x2F;nginx&#x2F;conf&#x2F;nginx.conf test is successfulReloading nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-5-反向代理"><a href="#2-5-反向代理" class="headerlink" title="2.5 反向代理"></a>2.5 反向代理</h4><p>代理服务器根据其代理对象的不同，可以分为正向代理服务器与反向代理服务器。这里<br>的“正”与“反”均是站在客户端角度来说的</p><h5 id="2-5-1-正向代理服务器"><a href="#2-5-1-正向代理服务器" class="headerlink" title="2.5.1 正向代理服务器"></a>2.5.1 正向代理服务器</h5><p>向代理是对客户端的代理。客户端 C 想要从服务端 S 获取资源，但由于某些原因不能，直接访问服务端，而是通过另外一台主机 P 向服务端发送请求。当服务端处理完毕请求后，将响应发送给主机 P，主机 P 在接收到来自服务端的响应后，将响应又转给了客户端 C。此时的主机 P，就称为客户端 C 的正向代理服务器。<br>客户端在使用正向代理服务器时是知道其要访问的目标服务器的地址等信息的。正向代理服务器是为服务用户（客户端）而架设的主机，与服务端无关，对服务器端透明<br><a href="https://ibb.co/JR7yytW">正向代理-1</a><br><a href="https://ibb.co/VT5B25b">正向代理-2</a><br><a href="https://ibb.co/3FhLxnL">正向代理-3</a></p><h5 id="2-5-2-反向代理服务器"><a href="#2-5-2-反向代理服务器" class="headerlink" title="2.5.2    反向代理服务器"></a>2.5.2    反向代理服务器</h5><p>反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器<br><a href="https://ibb.co/4YwpHD0">反向代理-1</a><br><a href="https://ibb.co/JC9kvQ6">反向代理-2</a><br><a href="https://ibb.co/fFsWnGG">反向代理-3</a></p><p><strong>负载均衡（Load Balancing）</strong>：就是将对请求的处理分摊到多个操作单元上进行。这个均衡是指在大批量访问前提下的一种基本均衡，并非是绝对的平均。对于 Web 工程中的负载均衡，就是将相同的 Web 应用部署到多个不同的 Web 服务器上，形成多个 Web 应用服务器。当请求到来时，由负载均衡服务器负责将请求按照事先设定好的比例向 Web 应用服务器进行分发，从而增加系统的整体吞吐量</p><p>软件负载均衡:<br>基本都是开源软件。例如：LVS、HAProxy、Nginx 等<br>该机群包含一台 Nginx 服务器，两台 Web服务器(node2和node3)。<br>修改nginx.conf文件</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">upstream</span> name</span><span class="token punctuation">&#123;</span>        <span class="token directive"><span class="token keyword">server</span> 192.168.40.102</span><span class="token punctuation">;</span>        <span class="token directive"><span class="token keyword">server</span> 192.168.40.133</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>       <span class="token directive"><span class="token keyword">listen</span>  <span class="token number">80</span></span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">server_name</span> www.sxthenhao.com</span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">access_log</span>   logs/myfmt.log  myfmt</span><span class="token punctuation">;</span>       <span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">&#123;</span>           <span class="token directive"><span class="token keyword">root</span> /mnt</span><span class="token punctuation">;</span>           <span class="token directive"><span class="token keyword">autoindex</span> <span class="token boolean">on</span></span><span class="token punctuation">;</span>       <span class="token punctuation">&#125;</span>       <span class="token directive"><span class="token keyword">location</span> /toms</span> <span class="token punctuation">&#123;</span>           <span class="token directive"><span class="token keyword">proxy_pass</span> http://name/</span><span class="token punctuation">;</span>       <span class="token punctuation">&#125;</span><span class="token comment">#  name要一致</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重启nginx，请求测试：<a href="http://www.sxthenhao.com/toms%EF%BC%8C%E5%8F%91%E7%8E%B0%E5%B7%B2%E7%BB%8F%E5%AE%9E%E7%8E%B0%E4%BA%86%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%82%EF%BC%88%E4%B8%AD%E5%B0%8F%E4%BC%81%E4%B8%9A%E4%B8%80%E8%88%AC%E4%BD%BF%E7%94%A8%E8%AF%A5%E6%96%B9%E5%BC%8F%EF%BC%89">http://www.sxthenhao.com/toms，发现已经实现了负载均衡。（中小企业一般使用该方式）</a></p><p>Nginx可以用</p><h4 id="2-6-Nginx调优"><a href="#2-6-Nginx调优" class="headerlink" title="2.6 Nginx调优"></a>2.6 Nginx调优</h4><h5 id="2-6-1-worker-processes-的设置"><a href="#2-6-1-worker-processes-的设置" class="headerlink" title="2.6.1 worker_processes  的设置"></a>2.6.1 worker_processes  的设置</h5><p><strong>打开 nginx.conf 配置文件，可以看到 worker_processes 的默认值为 1。</strong><br>    worker_processes，工作进程，用于指定 Nginx 的工作进程数量。该值应该设置为多少合适呢？其数值一般设置为 CPU 内核数量，或内核数量的整数倍。注意，现代的 CPU 一般都是多核的，即一块 CPU 中包含多个内核。若当前系统具有 2 块 CPU，而每块 CPU 中包含 2 个内核，那么，worker_processes 的值一般可以设置为 4 或 8。当然，也可以设置为 2。</p><p>不过需要注意，该值不仅仅取决于 CPU 内核数量，还与硬盘数量及负载均衡模式相关。在不确定时可以指定其值为 auto</p><h5 id="2-6-2-worker-cpu-affinity-的设置"><a href="#2-6-2-worker-cpu-affinity-的设置" class="headerlink" title="2.6.2 worker_cpu_affinity  的设置"></a>2.6.2 worker_cpu_affinity  的设置</h5><p>为了进一步提高系统性能，我们会将 worker 进程与具体的内核进行绑定。该绑定操作是通过 worker_cpu_affinity 属性进行设置的。affinity，密切关系。不过，若指定 worker_processes 的值为 auto，则无法设置 worker_cpu_affinity。</p><p>该设置是通过二进制进行的。每个内核使用一个二进制位表示，0 代表内核关闭，1 代表内核开启。也就是说，有几个内核，就需要使用几个二进制位</p><h4 id="2-7-session共享"><a href="#2-7-session共享" class="headerlink" title="2.7 session共享"></a>2.7 session共享</h4><p><a href="https://ibb.co/fCsThLT">session共享</a><br>http协议是无状态的，即你连续访问某个网页100次和访问1次对服务器来说是没有区别对待的，因为它记不住你。那么，在一些场合，确实需要服务器记住当前用户怎么办？比如用户登录邮箱后，接下来要收邮件、写邮件，总不能每次操作都让用户输入用户名和密码吧，为了解决这个问题，session的方案就被提了出来，事实上它并不是什么新技术，而且也不能脱离http协议以及任何现有的web技术<br>session的常见实现形式是会话cookie（session cookie），即未设置过期时间的cookie，这个cookie的默认生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。实现机制是当用户发起一个请求的时候，服务器会检查该请求中是否包含sessionid，如果未包含，则系统会创造一个名为JSESSIONID的输出 cookie返回给浏览器(只放入内存，并不存在硬盘中)，并将其以HashTable的形式写到服务器的内存里面；当已经包含sessionid是，服务端会检查找到与该session相匹配的信息，如果存在则直接使用该sessionid，若不存在则重新生成新的 session。这里需要注意的是session始终是有服务端创建的，并非浏览器自己生成的。　但是浏览器的cookie被禁止后session就需要用get方法的URL重写的机制或使用POST方法提交隐藏表单的形式来实现<br>首先我们应该明白，为什么要实现共享，如果你的网站是存放在一个机器上，那么是不存在这个问题的，因为会话数据就在这台机器，但是如果你使用了负载均衡把请求分发到不同的机器呢？这个时候会话id在客户端是没有问题的，但是如果用户的两次请求到了两台不同的机器，而它的session数据可能存在其中一台机器，这个时候就会出现取不到session数据的情况，于是session的共享就成了一个问题</p><h5 id="2-7-1-session一致性解决方案"><a href="#2-7-1-session一致性解决方案" class="headerlink" title="2.7.1 session一致性解决方案"></a>2.7.1 session一致性解决方案</h5><ol><li>session复制<br>tomcat 本身带有复制session的功能。（基本不用）</li><li>共享session<br>需要专门管理session的软件，<br>memcached 缓存服务，可以和tomcat整合，帮助tomcat共享管理session<br><a href="https://ibb.co/y0Y3sKd">图例</a></li></ol><h5 id="2-7-2-安装jdk-tomcat-memcached"><a href="#2-7-2-安装jdk-tomcat-memcached" class="headerlink" title="2.7.2 安装jdk,tomcat,memcached"></a>2.7.2 安装jdk,tomcat,memcached</h5><h6 id="2-7-2-1-node2和node3上安装jdk和tomcat"><a href="#2-7-2-1-node2和node3上安装jdk和tomcat" class="headerlink" title="2.7.2.1    node2和node3上安装jdk和tomcat"></a>2.7.2.1    node2和node3上安装jdk和tomcat</h6><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node2 apps]# rpm -ivh jdk-7u80-linux-x64.rpm[root@node2 apps]# find &#x2F; -name &#39;*java*&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>#可以看出/usr/java/jdk1.7.0_80/<br>配置环境变量</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node2 jdk1.7.0_80]# vim &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加入以下两行代码</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.7.0_80export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>让文件生效：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@node2 apps]# source &#x2F;etc&#x2F;profile[root@node2 apps]# jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>13894 Jps  #说明jdk安装配置成功</p><p>解压apache-tomcat-7.0.69.tar.gz<br>修改webapps/dGROOT/index.jsp,dG全删后，添加:<br>from 192.168.20.102 session=&lt;%=session.getId()%&gt;<br>另外一台同样的安装配置操作。<br>然后分别访问node2和node3都可以正常，刷新session也不会变。<br>修改nginx.conf<br>    upstream rss {<br>        server 192.168.20.102:8080;<br>        server 192.168.20.103:8080;<br>}<br>访问测试<a href="http://www.sxthenhao.com/toms%EF%BC%8C%E5%88%B7%E6%96%B0session%E4%B8%80%E7%9B%B4%E6%94%B9%E5%8F%98">http://www.sxthenhao.com/toms，刷新session一直改变</a></p><h6 id="2-7-2-2-nginx1上安装memcached"><a href="#2-7-2-2-nginx1上安装memcached" class="headerlink" title="2.7.2.2    nginx1上安装memcached"></a>2.7.2.2    nginx1上安装memcached</h6><ol><li><p>安装libevent<br>a)    yum install libevent -y</p></li><li><p>安装memcached<br>a)    yum install memcached  -y</p></li><li><p>启动memcached<br>memcached -d -m 128m -p 11211 -l 192.168.40.105 -u root -P /opt/<br>-d:后台启动服务<br>-m:缓存大小<br>-p：端口<br>-l:IP<br>-P:服务器启动后的系统进程ID，存储的文件<br>-u:服务器启动是以哪个用户名作为管理用户</p></li></ol><h5 id="2-7-3-配置session共享"><a href="#2-7-3-配置session共享" class="headerlink" title="2.7.3 配置session共享"></a>2.7.3 配置session共享</h5><p>1、拷贝jar到tomcat的lib下，jar包见附件<br>2、配置tomcat，每个tomcat里面的context.xml中加入</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Manager</span> <span class="token attr-name">className</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>de.javakaffee.web.msm.MemcachedBackupSessionManager<span class="token punctuation">"</span></span> <span class="token attr-name">memcachedNodes</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>n1:192.168.40.102:11211<span class="token punctuation">"</span></span>     <span class="token attr-name">sticky</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span>     <span class="token attr-name">lockingMode</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>auto<span class="token punctuation">"</span></span>    <span class="token attr-name">sessionBackupAsync</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token attr-name">requestUriIgnorePattern</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>.*\.(ico|png|gif|jpg|css|js)$<span class="token punctuation">"</span></span>    <span class="token attr-name">sessionBackupTimeout</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1000<span class="token punctuation">"</span></span> <span class="token attr-name">transcoderFactoryClass</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>tomcat添加jar包和配置信息之后需要重启</p><h3 id="3-nginx-参考手册"><a href="#3-nginx-参考手册" class="headerlink" title="3 nginx 参考手册"></a>3 nginx 参考手册</h3><p><a href="https://maiimg.com/free/?e=dn0e4m3mWRKCI6">参考笔记</a></p><p>期间遇到的问题：</p><p>服务器无响应：引起原因多为端口未开发<br><a href="https://www.cnblogs.com/stulzq/p/9808504.html">firewall命令参考</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#查看已开启的端口firewall-cmd --list-ports#查看防火墙状态firewall-cmd --state#开启防火墙systemctl start firewalld#开启端口firewall-cmd --zone&#x3D;public --add-port&#x3D;8888&#x2F;tcp --permanent#重启防火墙firewall-cmd --reload#关闭防火墙systemctl stop firewalld<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>舆情分析</title>
      <link href="/2021/12/21/yu-qing-fen-xi/"/>
      <url>/2021/12/21/yu-qing-fen-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="tap爬虫"><a href="#tap爬虫" class="headerlink" title="tap爬虫"></a>tap爬虫</h1><h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><ul><li>获取玩家反馈基调,分析玩家全体关注点;</li></ul><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">import</span> os<span class="token keyword">import</span> time<span class="token keyword">import</span> json<span class="token keyword">import</span> random<span class="token keyword">import</span> random<span class="token keyword">import</span> requests<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree<span class="token comment"># 请求头</span>headers <span class="token operator">=</span> <span class="token punctuation">&#123;</span> <span class="token string">"User_Agent"</span> <span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36"</span><span class="token punctuation">&#125;</span><span class="token keyword">class</span> <span class="token class-name">tapspider</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">id</span><span class="token punctuation">,</span>page<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span><span class="token builtin">id</span> <span class="token operator">=</span> <span class="token builtin">id</span>         self<span class="token punctuation">.</span>page <span class="token operator">=</span> page         self<span class="token punctuation">.</span><span class="token builtin">list</span> <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">get_url_list</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>page<span class="token punctuation">)</span><span class="token punctuation">:</span>            url <span class="token operator">=</span> <span class="token string">'https://www.taptap.com/app/'</span> <span class="token operator">+</span> \                <span class="token builtin">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'/topic?type=feed&amp;sort=created&amp;page='</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>            request <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>            <span class="token comment"># xpath解析获取玩家详情页</span>            xpath_data <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>request<span class="token punctuation">.</span>content<span class="token punctuation">)</span>            <span class="token comment"># 获得用户帖子详情页</span>            playerid_url <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                <span class="token string">'//div[@class="common-v2-list topic-item common-box-card js-ugc-item js-moment-item"]/@href'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span><span class="token builtin">list</span><span class="token punctuation">.</span>extend<span class="token punctuation">(</span>playerid_url<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">parse_list</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        ame_list<span class="token punctuation">,</span> create_time_list<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> play_time_list<span class="token punctuation">,</span> title_list<span class="token punctuation">,</span> content_list<span class="token punctuation">,</span> img_list<span class="token punctuation">,</span> reply_list <span class="token operator">=</span> <span class="token punctuation">[</span>            <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span><span class="token builtin">list</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token string">'topic'</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span>                request <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>                xpath_data <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>request<span class="token punctuation">.</span>content<span class="token punctuation">)</span>                <span class="token comment"># 玩家昵称</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    name <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//div/a[@class="user-name "]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                    name_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">)</span>                <span class="token keyword">except</span> IndexError<span class="token punctuation">:</span>                    name <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//div/div[@class="user-name-identity topic-author__app"]/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                    name_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">)</span>                <span class="token comment"># 帖子创建时间</span>                create_time <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div/ul/li/span/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                create_time <span class="token operator">=</span> create_time<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">)</span>                create_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>create_time<span class="token punctuation">)</span>                <span class="token comment"># 帖子所属的分区</span>                label <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                    <span class="token string">'//li[@class="topic-main_labels"]/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">)</span>                <span class="token comment"># 玩家游戏时间</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    playtime <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//li/span[@class="text-score-time"]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                    play_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>playtime<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    play_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>                    <span class="token comment"># 帖子标题</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    title <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//div[@class="top-title-author"]/./p/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>                    title_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>title<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">)</span>                    <span class="token comment"># 帖子内容</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    content <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//div/div[@class="bbcode-body bbcode-body-v2 js-open-bbcode-image js-translate-content"]//text()'</span><span class="token punctuation">)</span>                    etmpy <span class="token operator">=</span> <span class="token string">''</span>                    <span class="token keyword">for</span> text <span class="token keyword">in</span> content<span class="token punctuation">:</span>                        etmpy <span class="token operator">=</span> etmpy<span class="token operator">+</span><span class="token string">' '</span> <span class="token operator">+</span> \                            re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"(\s)|(\n)|(' ')|(,)"</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>                        content <span class="token operator">=</span> etmpy                    content_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>content<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> <span class="token string">'con'</span><span class="token punctuation">)</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    <span class="token comment"># 图片链接</span>                    img <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div/div/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>                    img_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> <span class="token string">'img'</span><span class="token punctuation">)</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    <span class="token comment"># 回复</span>                    reply <span class="token operator">=</span> xpath_data<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>                        <span class="token string">'//div/div/div[@class="item-text-body bbcode-body bbcode-body-v2 js-open-bbcode-image"]/text()'</span><span class="token punctuation">)</span>                    reply_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>reply<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> <span class="token string">'re'</span><span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token comment">#解析json</span>                <span class="token keyword">if</span> <span class="token string">'video'</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span>                    <span class="token builtin">id</span> <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">'\d+'</span><span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span>                    user_url <span class="token operator">=</span> <span class="token string">'https://www.taptap.com/webapiv2/video/v2/detail?id='</span><span class="token operator">+</span><span class="token builtin">id</span> <span class="token operator">+</span> \                        <span class="token string">'&amp;X-UA=V%3D1%26PN%3DWebApp%26LANG%3Dzh_CN%26VN_CODE%3D3%26VN%3D0.1.0%26LOC%3DCN%26PLT%3DPC%26DS%3DAndroid%26UID%3D7d018504-3322-4788-8c64-024ea433da5d%26VID%3D345765606%26DT%3DPC'</span>                <span class="token comment"># 解析网址</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token builtin">id</span> <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">'\d+'</span><span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span>                    user_url <span class="token operator">=</span> <span class="token string">'https://www.taptap.com/webapiv2/moment/v2/detail?id='</span> <span class="token operator">+</span> <span class="token builtin">id</span> <span class="token operator">+</span> \                        <span class="token string">'&amp;X-UA=V%3D1%26PN%3DWebApp%26LANG%3Dzh_CN%26VN_CODE%3D3%26VN%3D0.1.0%26LOC%3DCN%26PLT%3DPC%26DS%3DAndroid%26UID%3D7d018504-3322-4788-8c64-024ea433da5d%26VID%3D345765606%26DT%3DPC'</span>                    <span class="token comment"># 解析网</span>                request <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>user_url<span class="token punctuation">)</span>                response <span class="token operator">=</span> request<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment">#用户昵称</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    name <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>                    name_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    name <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'video'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>                    namelist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name_<span class="token punctuation">)</span>                <span class="token comment"># 帖子创建时间</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    create_time <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'created_time'</span><span class="token punctuation">]</span>                    time_local <span class="token operator">=</span> time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span>create_time<span class="token punctuation">)</span>                    <span class="token comment"># 转换成新的时间格式()</span>                    create_time <span class="token operator">=</span> time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y/%m/%d"</span><span class="token punctuation">,</span> time_local<span class="token punctuation">)</span>                    create_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>create_time<span class="token punctuation">)</span>                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>                    create_time <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'video'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'created_time'</span><span class="token punctuation">]</span>                    time_local <span class="token operator">=</span> time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span>create_time<span class="token punctuation">)</span>                    <span class="token comment"># 转换成新的时间格式()</span>                    create_time <span class="token operator">=</span> time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y/%m/%d"</span><span class="token punctuation">,</span> time_local<span class="token punctuation">)</span>                    create_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>create_time<span class="token punctuation">)</span>                <span class="token keyword">except</span><span class="token punctuation">:</span>                    play_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>                <span class="token comment">#游戏时长</span>                play_time_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>                <span class="token comment">#帖子分区</span>                label <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'groups'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'group_label'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>                label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">)</span>                <span class="token comment">#图片链接</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    img <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'extended_entities'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'images'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span>                    img_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>                    img_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>                <span class="token comment">### 标题</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    title <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'sharing'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'description'</span><span class="token punctuation">]</span>                    title_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>title<span class="token punctuation">)</span>                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>                    title <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'extended_entities'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'videos'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>                    title_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>title<span class="token punctuation">)</span>                <span class="token comment"># 内容</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    content <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'moment'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'contents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'raw_text'</span><span class="token punctuation">]</span>                    content_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>content<span class="token punctuation">)</span>                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>                    content <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'video'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'intro'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>                    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'[\u4e00-\u9fa5].*\Z'</span><span class="token punctuation">)</span>                    content <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> content<span class="token punctuation">)</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span>                    content <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'&lt;/p>'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> content<span class="token punctuation">)</span>                    content_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>content<span class="token punctuation">)</span>                <span class="token comment">#回复</span>                reply_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>             <span class="token comment"># 休眠</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span>random<span class="token punctuation">.</span>randrange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 保存为字典</span>        data_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"name"</span><span class="token punctuation">:</span> name_list<span class="token punctuation">,</span> <span class="token string">"createtime"</span><span class="token punctuation">:</span> create_time_list<span class="token punctuation">,</span> <span class="token string">"label"</span><span class="token punctuation">:</span> label_list<span class="token punctuation">,</span> <span class="token string">"playtime"</span><span class="token punctuation">:</span> play_time_list<span class="token punctuation">,</span>                     <span class="token string">"title"</span><span class="token punctuation">:</span> title_list<span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> content_list<span class="token punctuation">,</span> <span class="token string">"img"</span><span class="token punctuation">:</span> img_list<span class="token punctuation">,</span> <span class="token string">"reply"</span><span class="token punctuation">:</span> reply_list<span class="token punctuation">,</span> <span class="token string">"user_url"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span><span class="token builtin">list</span><span class="token punctuation">&#125;</span>        <span class="token keyword">return</span> data_dict    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        path <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span>        filepath <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">'\%s.json'</span> <span class="token operator">%</span> name<span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">,</span> filepath<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        excel_path<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'%s.xlsx'</span><span class="token operator">%</span>name<span class="token punctuation">)</span>        excel <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span>excel_path<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>path<span class="token operator">+</span><span class="token string">'\%s.json'</span> <span class="token operator">%</span> name<span class="token punctuation">,</span>excel_path<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>        data <span class="token operator">=</span> self<span class="token punctuation">.</span>parse_list<span class="token punctuation">(</span><span class="token punctuation">)</span>        json <span class="token operator">=</span> self<span class="token punctuation">.</span>save<span class="token punctuation">(</span>name<span class="token punctuation">,</span><span class="token builtin">dict</span><span class="token operator">=</span>data<span class="token punctuation">)</span><span class="token keyword">if</span> __name__<span class="token operator">==</span><span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据展示"><a href="#数据展示" class="headerlink" title="数据展示"></a>数据展示</h2><p><img src="tap.jpg"></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><object data="./舆情分析/社区舆情分析报告.pdf" type="application/pdf" width="80%" height="80%">]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
